{
  "Anthropic": {
    "provider_info": {
      "id": "Anthropic",
      "object": "provider",
      "created": 0,
      "url": "https://console.anthropic.com",
      "label": "Anthropic API"
    },
    "models": [
      "claude-opus-4-1-20250805",
      "claude-sonnet-4-20250514",
      "claude-opus-4-20250522",
      "claude-3-7-sonnet-20250219",
      "claude-3-5-sonnet-20241022",
      "claude-3-5-haiku-20241022",
      "claude-3-opus-20240229",
      "claude-3-sonnet-20240229",
      "claude-3-haiku-20240307",
      "claude-opus-4-1-latest",
      "claude-sonnet-4-latest",
      "claude-3-5-sonnet-latest",
      "claude-3-5-haiku-latest",
      "claude-3-opus-latest"
    ],
    "model_count": 14
  },
  "ApiAirforce": {
    "provider_info": {
      "id": "ApiAirforce",
      "object": "provider",
      "created": 0,
      "url": "https://api.airforce",
      "label": "Api.Airforce"
    },
    "models": [
      "claude-haiku",
      "dall-e-3",
      "deepseek-v3",
      "deepseek-v3.1",
      "flux-dev",
      "flux-krea-dev",
      "flux-schnell",
      "gemini-2.0-flash",
      "gemini-2.5-flash",
      "gemini-2.5-pro",
      "glm-4.5",
      "glm-4.5-air",
      "gpt-4o-mini",
      "gpt-5-mini",
      "gpt-oss-120b",
      "gpt-oss-20b",
      "grok-4",
      "imagen-3",
      "imagen-4",
      "kimi-k2",
      "llama-4-maverick",
      "llama-4-scout",
      "mistral-large",
      "mistral-medium",
      "mistral-small",
      "openchat-3.5",
      "pixtral",
      "qwen3-235b",
      "qwen3-coder",
      "sdxl",
      "sonar-reasoning"
    ],
    "model_count": 31
  },
  "Azure": {
    "provider_info": {
      "id": "Azure",
      "object": "provider",
      "created": 0,
      "url": "https://ai.azure.com",
      "label": "Azure ‚òÅÔ∏è"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/Azure/models"
  },
  "BingCreateImages": {
    "provider_info": {
      "id": "BingCreateImages",
      "object": "provider",
      "created": 0,
      "url": "https://www.bing.com/images/create",
      "label": "Microsoft Designer in Bing"
    },
    "models": [
      "dall-e-3"
    ],
    "model_count": 1
  },
  "BlackForestLabs_Flux1Dev": {
    "provider_info": {
      "id": "BlackForestLabs_Flux1Dev",
      "object": "provider",
      "created": 0,
      "url": "https://black-forest-labs-flux-1-dev.hf.space",
      "label": "BlackForestLabs Flux-1-Dev"
    },
    "models": [
      "flux-dev",
      "flux"
    ],
    "model_count": 2
  },
  "BlackForestLabs_Flux1KontextDev": {
    "provider_info": {
      "id": "BlackForestLabs_Flux1KontextDev",
      "object": "provider",
      "created": 0,
      "url": "https://black-forest-labs-flux-1-kontext-dev.hf.space",
      "label": "BlackForestLabs Flux-1-Kontext-Dev"
    },
    "models": [
      "flux-kontext-dev"
    ],
    "model_count": 1
  },
  "BlackboxPro": {
    "provider_info": {
      "id": "BlackboxPro",
      "object": "provider",
      "created": 0,
      "url": "https://www.blackbox.ai",
      "label": "Blackbox AI Pro"
    },
    "models": [],
    "model_count": 0
  },
  "CachedSearch": {
    "provider_info": {
      "id": "CachedSearch",
      "object": "provider",
      "created": 0,
      "url": null,
      "label": null
    },
    "models": [],
    "model_count": 0
  },
  "Cerebras": {
    "provider_info": {
      "id": "Cerebras",
      "object": "provider",
      "created": 0,
      "url": "https://inference.cerebras.ai/",
      "label": "Cerebras Inference"
    },
    "models": [
      "llama3.1-70b",
      "llama3.1-8b",
      "llama-3.3-70b",
      "deepseek-r1-distill-llama-70b"
    ],
    "model_count": 4
  },
  "Chatai": {
    "provider_info": {
      "id": "Chatai",
      "object": "provider",
      "created": 0,
      "url": "https://chatai.aritek.app",
      "label": "Chatai"
    },
    "models": [
      "gpt-4o-mini"
    ],
    "model_count": 1
  },
  "Claude": {
    "provider_info": {
      "id": "Claude",
      "object": "provider",
      "created": 0,
      "url": "https://claude.ai",
      "label": "Claude üí•"
    },
    "models": [
      "claude-opus-4-1-20250805",
      "claude-sonnet-4-20250514"
    ],
    "model_count": 2
  },
  "Cloudflare": {
    "provider_info": {
      "id": "Cloudflare",
      "object": "provider",
      "created": 0,
      "url": "https://playground.ai.cloudflare.com",
      "label": "Cloudflare AI"
    },
    "models": [
      "deepseek-coder-6.7b-base",
      "deepseek-coder-6.7b",
      "deepseek-math-7b",
      "deepseek-distill-qwen-32b",
      "discolm-german-7b-v1",
      "falcon-7b",
      "gemma-3-12b",
      "gemma-7b",
      "hermes-2-pro-mistral-7b",
      "llama-2-13b",
      "llama-2-7b-fp16",
      "llama-2-7b",
      "llama-3-8b",
      "llama-3.1-8b",
      "llama-3.2-11b-vision",
      "llama-3.2-1b",
      "llama-3.2-3b",
      "llama-3.3-70b",
      "llama-4-scout",
      "llama-guard-3-8b",
      "llamaguard-7b",
      "mistral-7b-v0.1",
      "mistral-7b-v0.2",
      "mistral-small-3.1-24b",
      "neural-7b-v3-1",
      "openchat-3.5-0106",
      "openhermes-2.5-mistral-7b",
      "phi-2",
      "qwen1.5-0.5b",
      "qwen-1.5-1.8b",
      "qwen-1.5-14b",
      "qwen-1.5-7b",
      "qwen-2.5-coder-32b",
      "qwq-32b",
      "sqlcoder-7b-2",
      "starling-lm-7b-beta",
      "tinyllama-1.1b-v1.0",
      "una-cybertron-7b-v2-bf16",
      "zephyr-7b-beta"
    ],
    "model_count": 39
  },
  "Cohere": {
    "provider_info": {
      "id": "Cohere",
      "object": "provider",
      "created": 0,
      "url": "https://cohere.com",
      "label": "Cohere API"
    },
    "models": [],
    "model_count": 0
  },
  "CohereForAI_C4AI_Command": {
    "provider_info": {
      "id": "CohereForAI_C4AI_Command",
      "object": "provider",
      "created": 0,
      "url": "https://coherelabs-c4ai-command.hf.space",
      "label": "CohereForAI C4AI Command"
    },
    "models": [
      "command-a-03-2025",
      "command-r-plus-08-2024",
      "command-r-08-2024",
      "command-r-plus",
      "command-r",
      "command-r7b-12-2024",
      "command-r7b-arabic-02-2025"
    ],
    "model_count": 7
  },
  "Copilot": {
    "provider_info": {
      "id": "Copilot",
      "object": "provider",
      "created": 0,
      "url": "https://copilot.microsoft.com",
      "label": "Microsoft Copilot"
    },
    "models": [
      "Copilot",
      "Think Deeper",
      "Smart (GPT-5)",
      "Study"
    ],
    "model_count": 4
  },
  "CopilotAccount": {
    "provider_info": {
      "id": "CopilotAccount",
      "object": "provider",
      "created": 0,
      "url": "https://copilot.microsoft.com",
      "label": "Microsoft Copilot"
    },
    "models": [
      "Copilot",
      "Think Deeper",
      "Smart (GPT-5)",
      "Study"
    ],
    "model_count": 4
  },
  "Custom": {
    "provider_info": {
      "id": "Custom",
      "object": "provider",
      "created": 0,
      "url": null,
      "label": "Custom Provider"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/Custom/models"
  },
  "DeepInfra": {
    "provider_info": {
      "id": "DeepInfra",
      "object": "provider",
      "created": 0,
      "url": "https://deepinfra.com",
      "label": null
    },
    "models": [
      "allenai/olmOCR-7B-1025",
      "PaddlePaddle/PaddleOCR-VL-0.9B",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "zai-org/GLM-4.6",
      "deepseek-ai/DeepSeek-V3.2-Exp",
      "deepseek-ai/DeepSeek-V3.1-Terminus",
      "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "moonshotai/Kimi-K2-Instruct-0905",
      "deepseek-ai/DeepSeek-V3.1",
      "openai/gpt-oss-120b",
      "openai/gpt-oss-20b",
      "allenai/olmOCR-7B-0825",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "zai-org/GLM-4.5",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "deepseek-ai/DeepSeek-R1-0528-Turbo",
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-30B-A3B",
      "Qwen/Qwen3-32B",
      "Qwen/Qwen3-14B",
      "deepseek-ai/DeepSeek-V3-0324-Turbo",
      "deepseek-ai/DeepSeek-Prover-V2-671B",
      "meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo",
      "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "deepseek-ai/DeepSeek-R1-0528",
      "deepseek-ai/DeepSeek-V3-0324",
      "mistralai/Devstral-Small-2507",
      "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "microsoft/phi-4-reasoning-plus",
      "meta-llama/Llama-Guard-4-12B",
      "Qwen/QwQ-32B",
      "anthropic/claude-4-opus",
      "anthropic/claude-4-sonnet",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
      "google/gemma-3-27b-it",
      "google/gemma-3-12b-it",
      "google/gemma-3-4b-it",
      "microsoft/Phi-4-multimodal-instruct",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "deepseek-ai/DeepSeek-V3",
      "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "meta-llama/Llama-3.3-70B-Instruct",
      "microsoft/phi-4"
    ],
    "model_count": 47
  },
  "DeepSeek": {
    "provider_info": {
      "id": "DeepSeek",
      "object": "provider",
      "created": 0,
      "url": "https://platform.deepseek.com",
      "label": "DeepSeek API"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/DeepSeek/models"
  },
  "DeepseekAI_JanusPro7b": {
    "provider_info": {
      "id": "DeepseekAI_JanusPro7b",
      "object": "provider",
      "created": 0,
      "url": "https://huggingface.co/spaces/deepseek-ai/Janus-Pro-7B",
      "label": "DeepseekAI Janus-Pro-7B"
    },
    "models": [
      "janus-pro-7b",
      "janus-pro-7b-image"
    ],
    "model_count": 2
  },
  "FenayAI": {
    "provider_info": {
      "id": "FenayAI",
      "object": "provider",
      "created": 0,
      "url": "https://fenayai.com",
      "label": null
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/FenayAI/models"
  },
  "GLM": {
    "provider_info": {
      "id": "GLM",
      "object": "provider",
      "created": 0,
      "url": "https://chat.z.ai",
      "label": null
    },
    "models": [
      "GLM-4.6",
      "GLM-4.5V",
      "GLM-4.5",
      "GLM-4.5-Air",
      "GLM-4-32B",
      "GLM-4.1V-9B-Thinking",
      "Z1-Rumination",
      "Z1-32B",
      "ChatGLM",
      "0808-360B-DR"
    ],
    "model_count": 10
  },
  "Gemini": {
    "provider_info": {
      "id": "Gemini",
      "object": "provider",
      "created": 0,
      "url": "https://gemini.google.com",
      "label": "Google Gemini"
    },
    "models": [
      "gemini-2.5-flash",
      "gemini-2.5-pro"
    ],
    "model_count": 2
  },
  "GeminiCLI": {
    "provider_info": {
      "id": "GeminiCLI",
      "object": "provider",
      "created": 0,
      "url": null,
      "label": "Google Gemini CLI"
    },
    "models": [
      "gemini-2.5-pro",
      "gemini-2.5-flash"
    ],
    "model_count": 2
  },
  "GeminiPro": {
    "provider_info": {
      "id": "GeminiPro",
      "object": "provider",
      "created": 0,
      "url": "https://ai.google.dev",
      "label": "Google Gemini API"
    },
    "models": [
      "gemini-2.0-flash",
      "gemini-2.0-flash-lite",
      "gemini-2.0-flash-thinking-exp",
      "gemini-2.5-flash",
      "gemma-3-1b-it",
      "gemma-3-12b-it",
      "gemma-3-27b-it",
      "gemma-3-4b-it",
      "gemma-3n-e2b-it",
      "gemma-3n-e4b-it"
    ],
    "model_count": 10
  },
  "GigaChat": {
    "provider_info": {
      "id": "GigaChat",
      "object": "provider",
      "created": 0,
      "url": "https://developers.sber.ru/gigachat",
      "label": null
    },
    "models": [
      "GigaChat-2",
      "GigaChat-2-Pro",
      "GigaChat-2-Max",
      "GigaChat",
      "GigaChat-Pro",
      "GigaChat-Max"
    ],
    "model_count": 6
  },
  "GithubCopilot": {
    "provider_info": {
      "id": "GithubCopilot",
      "object": "provider",
      "created": 0,
      "url": "https://github.com/copilot",
      "label": "GitHub Copilot"
    },
    "models": [
      "o3-mini",
      "gemini-2.0-flash",
      "o4-mini",
      "gpt-4.1",
      "gpt-5-mini",
      "gpt-4o",
      "claude-3.5-sonnet",
      "gemini-2.5-pro",
      "claude-3.7-sonnet",
      "claude-4-sonnet",
      "o3",
      "gpt-5",
      "claude-3.7-sonnet-thinking",
      "claude-4-opus",
      "claude-3.7-sonnet-pro",
      "o1",
      "o1-mini",
      "o1-preview"
    ],
    "model_count": 18
  },
  "GithubCopilotAPI": {
    "provider_info": {
      "id": "GithubCopilotAPI",
      "object": "provider",
      "created": 0,
      "url": "https://github.com/copilot",
      "label": "GitHub Copilot API"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/GithubCopilotAPI/models"
  },
  "GlhfChat": {
    "provider_info": {
      "id": "GlhfChat",
      "object": "provider",
      "created": 0,
      "url": "https://glhf.chat",
      "label": null
    },
    "models": [
      "hf:meta-llama/Llama-3.1-405B-Instruct",
      "hf:meta-llama/Llama-3.3-70B-Instruct",
      "hf:deepseek-ai/DeepSeek-V3",
      "hf:Qwen/QwQ-32B-Preview",
      "hf:huihui-ai/Llama-3.3-70B-Instruct-abliterated",
      "hf:anthracite-org/magnum-v4-12b",
      "hf:meta-llama/Llama-3.1-70B-Instruct",
      "hf:meta-llama/Llama-3.1-8B-Instruct",
      "hf:meta-llama/Llama-3.2-3B-Instruct",
      "hf:meta-llama/Llama-3.2-11B-Vision-Instruct",
      "hf:meta-llama/Llama-3.2-90B-Vision-Instruct",
      "hf:Qwen/Qwen2.5-72B-Instruct",
      "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
      "hf:google/gemma-2-9b-it",
      "hf:google/gemma-2-27b-it",
      "hf:mistralai/Mistral-7B-Instruct-v0.3",
      "hf:mistralai/Mixtral-8x7B-Instruct-v0.1",
      "hf:mistralai/Mixtral-8x22B-Instruct-v0.1",
      "hf:NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
      "hf:Qwen/Qwen2.5-7B-Instruct",
      "hf:upstage/SOLAR-10.7B-Instruct-v1.0",
      "hf:nvidia/Llama-3.1-Nemotron-70B-Instruct-HF"
    ],
    "model_count": 22
  },
  "GoogleSearch": {
    "provider_info": {
      "id": "GoogleSearch",
      "object": "provider",
      "created": 0,
      "url": "https://google.com",
      "label": "Google Search"
    },
    "models": [],
    "model_count": 0
  },
  "Grok": {
    "provider_info": {
      "id": "Grok",
      "object": "provider",
      "created": 0,
      "url": "https://grok.com",
      "label": "Grok AI"
    },
    "models": [
      "grok-4",
      "grok-4-heavy",
      "grok-4-reasoning",
      "grok-3",
      "grok-3-reasoning",
      "grok-3-mini",
      "grok-3-mini-reasoning",
      "grok-2",
      "grok-2-image",
      "grok-latest"
    ],
    "model_count": 10
  },
  "Groq": {
    "provider_info": {
      "id": "Groq",
      "object": "provider",
      "created": 0,
      "url": "https://console.groq.com/playground",
      "label": null
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/Groq/models"
  },
  "HailuoAI": {
    "provider_info": {
      "id": "HailuoAI",
      "object": "provider",
      "created": 0,
      "url": "https://www.hailuo.ai",
      "label": "Hailuo AI"
    },
    "models": [
      "minimax"
    ],
    "model_count": 1
  },
  "HuggingFace": {
    "provider_info": {
      "id": "HuggingFace",
      "object": "provider",
      "created": 0,
      "url": "https://huggingface.co",
      "label": null
    },
    "models": [
      "inclusionAI/Ling-1T",
      "zai-org/GLM-4.6",
      "deepseek-ai/DeepSeek-V3.2-Exp",
      "openai/gpt-oss-20b",
      "katanemo/Arch-Router-1.5B",
      "meta-llama/Llama-3.1-8B-Instruct",
      "openai/gpt-oss-120b",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "zai-org/GLM-4.6-FP8",
      "Qwen/Qwen3-8B",
      "moonshotai/Kimi-K2-Instruct-0905",
      "Qwen/Qwen3-4B-Instruct-2507",
      "meta-llama/Llama-3.1-8B",
      "deepseek-ai/DeepSeek-R1",
      "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "meta-llama/Llama-3.2-1B-Instruct",
      "Qwen/Qwen3-4B-Thinking-2507",
      "Qwen/Qwen3-1.7B",
      "dphn/Dolphin-Mistral-24B-Venice-Edition",
      "meta-llama/Llama-3.2-3B-Instruct",
      "Kwaipilot/KAT-Dev",
      "mistralai/Mistral-7B-Instruct-v0.2",
      "meta-llama/Meta-Llama-3-8B-Instruct",
      "meta-llama/Llama-3.3-70B-Instruct",
      "swiss-ai/Apertus-8B-Instruct-2509",
      "deepseek-ai/DeepSeek-V3.1-Terminus",
      "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "Qwen/Qwen2-VL-7B-Instruct",
      "CohereForAI/c4ai-command-r-plus-08-2024",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "Qwen/QwQ-32B",
      "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "Qwen/Qwen2.5-Coder-32B-Instruct",
      "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "mistralai/Mistral-Nemo-Instruct-2407",
      "microsoft/Phi-3.5-mini-instruct",
      "black-forest-labs/FLUX.1-dev",
      "black-forest-labs/FLUX.1-schnell",
      "Phr00t/Qwen-Image-Edit-Rapid-AIO",
      "tencent/HunyuanImage-3.0",
      "lightx2v/Qwen-Image-Lightning",
      "stabilityai/stable-diffusion-xl-base-1.0"
    ],
    "model_count": 43
  },
  "HuggingFaceAPI": {
    "provider_info": {
      "id": "HuggingFaceAPI",
      "object": "provider",
      "created": 0,
      "url": "https://api-inference.huggingface.com",
      "label": "HuggingFace (Text Generation)"
    },
    "models": [
      "inclusionAI/Ling-1T",
      "zai-org/GLM-4.6",
      "deepseek-ai/DeepSeek-V3.2-Exp",
      "openai/gpt-oss-20b",
      "katanemo/Arch-Router-1.5B",
      "meta-llama/Llama-3.1-8B-Instruct",
      "openai/gpt-oss-120b",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "zai-org/GLM-4.6-FP8",
      "Qwen/Qwen3-8B",
      "moonshotai/Kimi-K2-Instruct-0905",
      "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "Qwen/Qwen3-4B-Instruct-2507",
      "deepseek-ai/DeepSeek-R1",
      "mistralai/Mistral-7B-Instruct-v0.3",
      "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "meta-llama/Llama-3.2-1B-Instruct",
      "Qwen/Qwen3-4B-Thinking-2507",
      "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "Qwen/Qwen2.5-VL-7B-Instruct",
      "Qwen/Qwen3-1.7B",
      "dphn/Dolphin-Mistral-24B-Venice-Edition",
      "meta-llama/Llama-3.2-3B-Instruct",
      "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "Kwaipilot/KAT-Dev",
      "mistralai/Mistral-7B-Instruct-v0.2",
      "meta-llama/Meta-Llama-3-8B-Instruct",
      "meta-llama/Llama-3.3-70B-Instruct",
      "swiss-ai/Apertus-8B-Instruct-2509",
      "deepseek-ai/DeepSeek-V3.1-Terminus",
      "HuggingFaceH4/zephyr-7b-beta",
      "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "Qwen/Qwen3-32B",
      "zai-org/GLM-4.5-Air",
      "google/gemma-2-2b-it",
      "Qwen/Qwen2.5-1.5B-Instruct",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "HuggingFaceTB/SmolLM3-3B",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "deepseek-ai/DeepSeek-V3.1",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "moonshotai/Kimi-K2-Instruct",
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen2.5-7B-Instruct",
      "jinaai/ReaderLM-v2",
      "zai-org/GLM-4.5",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "meta-llama/Llama-Guard-3-8B",
      "google/gemma-3-12b-it",
      "Qwen/Qwen3-14B",
      "darkc0de/XortronCriminalComputingConfig",
      "zai-org/GLM-4.5V",
      "MLP-KTLim/llama-3-Korean-Bllossom-8B",
      "HumanLLMs/Human-Like-Mistral-Nemo-Instruct-2407",
      "deepseek-ai/DeepSeek-V3",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "Qwen/Qwen2.5-VL-72B-Instruct",
      "Qwen/QwQ-32B",
      "mlabonne/gemma-3-27b-it-abliterated",
      "DeepHat/DeepHat-V1-7B",
      "deepseek-ai/DeepSeek-R1-0528",
      "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
      "deepcogito/cogito-v2-preview-llama-405B",
      "NousResearch/Hermes-4-70B",
      "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "meta-llama/Llama-2-13b-chat-hf",
      "IlyaGusev/saiga_llama3_8b",
      "Sao10K/L3-70B-Euryale-v2.1",
      "meta-llama/Llama-3.1-405B-Instruct",
      "Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2",
      "inflatebot/MN-12B-Mag-Mell-R1",
      "Qwen/Qwen2.5-72B-Instruct",
      "Qwen/Qwen2.5-Coder-7B-Instruct",
      "google/gemma-2-2b-jpn-it",
      "CohereLabs/aya-expanse-8b",
      "CohereLabs/aya-expanse-32b",
      "FallenMerick/MN-Violet-Lotus-12B",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "SentientAGI/Dobby-Unhinged-Llama-3.3-70B",
      "deepseek-ai/DeepSeek-V3-0324",
      "Qwen/Qwen3-30B-A3B",
      "Qwen/Qwen3-235B-A22B",
      "Qwen/Qwen3-8B-Base",
      "SWE-bench/SWE-agent-LM-32B",
      "Intelligent-Internet/II-Medical-8B",
      "Intelligent-Internet/II-Medical-8B-1706",
      "zai-org/GLM-4.1V-9B-Thinking",
      "agentica-org/DeepSWE-Preview",
      "zai-org/GLM-4.5-Air-FP8",
      "baichuan-inc/Baichuan-M2-32B",
      "Nondzu/Mistral-7B-codealpaca-lora",
      "Intel/neural-chat-7b-v3-1",
      "ceadar-ie/FinanceConnect-13B",
      "GritLM/GritLM-7B",
      "speakleash/Bielik-7B-Instruct-v0.1",
      "Orenguteng/Llama-3-8B-Lexi-Uncensored",
      "allganize/Llama-3-Alpha-Ko-8B-Instruct",
      "yentinglin/Llama-3-Taiwan-70B-Instruct",
      "Casual-Autopsy/L3-Umbral-Mind-RP-v3.0-8B",
      "pentagoniac/SEMIKONG-70B",
      "meta-llama/Llama-3.1-70B-Instruct",
      "princeton-nlp/gemma-2-9b-it-SimPO",
      "unsloth/Meta-Llama-3.1-8B-Instruct",
      "NousResearch/Hermes-3-Llama-3.1-8B",
      "arcee-ai/Llama-3.1-SuperNova-Lite",
      "Qwen/Qwen2.5-Math-1.5B",
      "Qwen/Qwen2.5-32B-Instruct",
      "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2",
      "huihui-ai/Qwen2.5-32B-Instruct-abliterated",
      "AITeamVN/Vi-Qwen2-7B-RAG",
      "AITeamVN/Vi-Qwen2-1.5B-RAG",
      "arcee-ai/SuperNova-Medius",
      "Kortix/FastApply-7B-v1.0",
      "huihui-ai/Qwen2.5-72B-Instruct-abliterated",
      "gajesh/llama-3-2-1b-instruct-eigentuned",
      "Qwen/Qwen2.5-Coder-32B",
      "allenai/Llama-3.1-Tulu-3-70B",
      "huihui-ai/QwQ-32B-Preview-abliterated",
      "NovaSky-AI/Sky-T1-32B-Preview",
      "nvidia/AceMath-7B-Instruct",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated",
      "huihui-ai/Qwen2.5-14B-Instruct-1M-abliterated",
      "huihui-ai/Mistral-Small-24B-Instruct-2501-abliterated",
      "OddTheGreat/Machina_24B.V2",
      "PocketDoc/Dans-PersonalityEngine-V1.2.0-24b",
      "ByteDance-Seed/BFS-Prover-V1-7B",
      "google/gemma-3-27b-it",
      "zerofata/L3.3-GeneticLemonade-Final-70B",
      "yamatazen/EtherealAurora-12B",
      "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4",
      "huihui-ai/QwQ-32B-abliterated",
      "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "unsloth/gemma-3-27b-it",
      "nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
      "Qwen/Qwen2.5-VL-32B-Instruct",
      "huihui-ai/gemma-3-12b-it-abliterated",
      "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "Tesslate/Synthia-S1-27b",
      "Unbabel/M-Prometheus-7B",
      "zai-org/GLM-4-32B-0414",
      "facebook/KernelLLM",
      "INSAIT-Institute/MamayLM-Gemma-2-9B-IT-v0.1",
      "meta-llama/Llama-Guard-4-12B",
      "unsloth/Qwen3-8B",
      "Goekdeniz-Guelmez/Josiefied-Qwen3-8B-abliterated-v1",
      "AITeamVN/GRPO-VI-Qwen2-7B-RAG",
      "PocketDoc/Dans-PersonalityEngine-V1.3.0-24b",
      "a-m-team/AM-Thinking-v1",
      "Tongyi-Zhiwen/QwenLong-L1-32B",
      "LumiOpen/Llama-Poro-2-8B-Instruct",
      "MiniMaxAI/SynLogic-Mix-3-32B",
      "MiniMaxAI/SynLogic-7B",
      "Unbabel/Tower-Plus-2B",
      "Unbabel/Tower-Plus-9B",
      "Skywork/Skywork-SWE-32B",
      "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5",
      "MiniMaxAI/MiniMax-M1-80k",
      "moonshotai/Kimi-Dev-72B",
      "THU-KEG/LongWriter-Zero-32B",
      "baidu/ERNIE-4.5-21B-A3B-PT",
      "nvidia/OpenReasoning-Nemotron-32B",
      "nvidia/OpenReasoning-Nemotron-7B",
      "Tesslate/UIGEN-X-8B",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "deepcogito/cogito-v2-preview-llama-70B",
      "fdtn-ai/Foundation-Sec-8B-Instruct",
      "arcee-ai/AFM-4.5B",
      "NousResearch/Hermes-4-405B",
      "zai-org/GLM-4.5V-FP8",
      "aisingapore/Gemma-SEA-LION-v4-27B-IT",
      "swiss-ai/Apertus-70B-Instruct-2509",
      "Casual-Autopsy/L3-Super-Nova-RP-8B",
      "ReadyArt/Omega-Darker-Gaslight_The-Final-Forgotten-Fever-Dream-24B",
      "sophosympatheia/Strawberrylemonade-L3-70B-v1.1",
      "NeverSleep/Llama-3-Lumimaid-8B-v0.1-OAS",
      "sophosympatheia/New-Dawn-Llama-3-70B-32K-v1.0",
      "TheDrummer/Llama-3SOME-8B-v2",
      "crestf411/MN-Slush",
      "ReadyArt/Omega-Darker_The-Final-Directive-24B",
      "ReadyArt/Broken-Tutu-24B-Unslop-v2.0",
      "Retreatcost/KansenSakura-Zero-RP-12b",
      "google/gemma-3-27b-it"
    ],
    "model_count": 187
  },
  "HuggingFaceMedia": {
    "provider_info": {
      "id": "HuggingFaceMedia",
      "object": "provider",
      "created": 0,
      "url": "https://huggingface.co",
      "label": "HuggingFace"
    },
    "models": [
      "akhaliq/sora-2",
      "akhaliq/sora-2:fal-ai",
      "Wan-AI/Wan2.2-T2V-A14B",
      "Wan-AI/Wan2.2-T2V-A14B:fal-ai",
      "Wan-AI/Wan2.2-T2V-A14B:replicate",
      "Wan-AI/Wan2.2-TI2V-5B",
      "Wan-AI/Wan2.2-TI2V-5B:fal-ai",
      "Wan-AI/Wan2.2-TI2V-5B:replicate",
      "tencent/HunyuanVideo",
      "tencent/HunyuanVideo:fal-ai",
      "genmo/mochi-1-preview",
      "genmo/mochi-1-preview:fal-ai",
      "akhaliq/veo3.1-fast",
      "akhaliq/veo3.1-fast:fal-ai",
      "akhaliq/veo3.1-fast:replicate",
      "Wan-AI/Wan2.1-T2V-14B",
      "Wan-AI/Wan2.1-T2V-14B:novita",
      "Wan-AI/Wan2.1-T2V-14B:fal-ai",
      "Wan-AI/Wan2.1-T2V-14B:replicate",
      "Wan-AI/Wan2.1-T2V-1.3B",
      "Wan-AI/Wan2.1-T2V-1.3B:fal-ai",
      "Wan-AI/Wan2.1-T2V-1.3B:replicate",
      "zai-org/CogVideoX-5b",
      "zai-org/CogVideoX-5b:fal-ai",
      "Wan-AI/Wan2.2-T2V-A14B-Diffusers",
      "Wan-AI/Wan2.2-T2V-A14B-Diffusers:fal-ai",
      "Wan-AI/Wan2.2-T2V-A14B-Diffusers:replicate",
      "black-forest-labs/FLUX.1-dev",
      "black-forest-labs/FLUX.1-dev:nebius",
      "black-forest-labs/FLUX.1-dev:fal-ai",
      "black-forest-labs/FLUX.1-dev:together",
      "black-forest-labs/FLUX.1-dev:replicate",
      "black-forest-labs/FLUX.1-dev:hf-inference",
      "tencent/HunyuanImage-3.0",
      "tencent/HunyuanImage-3.0:fal-ai",
      "tencent/HunyuanImage-3.0:replicate",
      "black-forest-labs/FLUX.1-schnell",
      "black-forest-labs/FLUX.1-schnell:nebius",
      "black-forest-labs/FLUX.1-schnell:nscale",
      "black-forest-labs/FLUX.1-schnell:fal-ai",
      "black-forest-labs/FLUX.1-schnell:together",
      "black-forest-labs/FLUX.1-schnell:replicate",
      "black-forest-labs/FLUX.1-schnell:hf-inference",
      "stabilityai/stable-diffusion-xl-base-1.0",
      "stabilityai/stable-diffusion-xl-base-1.0:nscale",
      "stabilityai/stable-diffusion-xl-base-1.0:replicate",
      "stabilityai/stable-diffusion-xl-base-1.0:hf-inference",
      "Qwen/Qwen-Image",
      "Qwen/Qwen-Image:fal-ai",
      "Qwen/Qwen-Image:replicate",
      "stabilityai/stable-diffusion-3.5-large",
      "stabilityai/stable-diffusion-3.5-large:fal-ai",
      "tencent/SRPO",
      "tencent/SRPO:fal-ai",
      "black-forest-labs/FLUX.1-Krea-dev",
      "black-forest-labs/FLUX.1-Krea-dev:fal-ai",
      "black-forest-labs/FLUX.1-Krea-dev:replicate",
      "stabilityai/stable-diffusion-3-medium",
      "stabilityai/stable-diffusion-3-medium:fal-ai",
      "stabilityai/stable-diffusion-3-medium:replicate",
      "tencent/HunyuanImage-2.1",
      "tencent/HunyuanImage-2.1:fal-ai",
      "tencent/HunyuanImage-2.1:replicate",
      "ByteDance/SDXL-Lightning",
      "ByteDance/SDXL-Lightning:fal-ai",
      "ByteDance/Hyper-SD",
      "ByteDance/Hyper-SD:fal-ai",
      "ByteDance/Hyper-SD:replicate",
      "ByteDance/Hyper-SD:replicate",
      "stabilityai/stable-diffusion-3.5-medium",
      "stabilityai/stable-diffusion-3.5-medium:fal-ai",
      "Nishitbaria/Anime-style-flux-lora-Large",
      "Nishitbaria/Anime-style-flux-lora-Large:fal-ai",
      "Nishitbaria/Anime-style-flux-lora-Large:replicate",
      "flymy-ai/qwen-image-realism-lora",
      "flymy-ai/qwen-image-realism-lora:fal-ai",
      "Gourieff/Flux.1-Fashion-Enhancer-Lora",
      "Gourieff/Flux.1-Fashion-Enhancer-Lora:fal-ai",
      "Gourieff/Flux.1-Fashion-Enhancer-Lora:replicate",
      "stabilityai/stable-diffusion-3-medium-diffusers",
      "stabilityai/stable-diffusion-3-medium-diffusers:hf-inference",
      "XLabs-AI/flux-RealismLora",
      "XLabs-AI/flux-RealismLora:fal-ai",
      "XLabs-AI/flux-RealismLora:replicate",
      "davisbro/designer-architecture",
      "davisbro/designer-architecture:fal-ai",
      "davisbro/designer-architecture:replicate",
      "Shakker-Labs/FLUX.1-dev-LoRA-Logo-Design",
      "Shakker-Labs/FLUX.1-dev-LoRA-Logo-Design:fal-ai",
      "Shakker-Labs/FLUX.1-dev-LoRA-Logo-Design:replicate",
      "inuptia/asian-nudity-2",
      "inuptia/asian-nudity-2:fal-ai",
      "inuptia/asian-nudity-2:replicate",
      "Alpha-VLLM/Lumina-Image-2.0",
      "Alpha-VLLM/Lumina-Image-2.0:fal-ai",
      "minpeter/LoRA-FLUX-anime-style-v2",
      "minpeter/LoRA-FLUX-anime-style-v2:fal-ai",
      "minpeter/LoRA-FLUX-anime-style-v2:replicate",
      "HiDream-ai/HiDream-I1-Full",
      "HiDream-ai/HiDream-I1-Full:fal-ai",
      "bunnycore/Qwen-Aesthetic",
      "bunnycore/Qwen-Aesthetic:fal-ai",
      "olesheva/DavidLynch-Qwen-LoRA",
      "olesheva/DavidLynch-Qwen-LoRA:fal-ai",
      "flymy-ai/flux-dev-anne-hathaway-lora",
      "flymy-ai/flux-dev-anne-hathaway-lora:fal-ai",
      "flymy-ai/flux-dev-anne-hathaway-lora:replicate",
      "ostris/embroidery_style_lora_sdxl",
      "ostris/embroidery_style_lora_sdxl:fal-ai",
      "latent-consistency/lcm-lora-sdxl",
      "latent-consistency/lcm-lora-sdxl:fal-ai",
      "ntc-ai/SDXL-LoRA-slider.comic-portrait",
      "ntc-ai/SDXL-LoRA-slider.comic-portrait:fal-ai",
      "itzzdeep/youtube-thumbnails-sdxl-lora",
      "itzzdeep/youtube-thumbnails-sdxl-lora:fal-ai",
      "rajkumaralma/futureistic_fantasy_anime_sDXL",
      "rajkumaralma/futureistic_fantasy_anime_sDXL:fal-ai",
      "fofr/sdxl-emoji",
      "fofr/sdxl-emoji:fal-ai",
      "jbilcke-hf/flux-dev-panorama-lora-2",
      "jbilcke-hf/flux-dev-panorama-lora-2:fal-ai",
      "jbilcke-hf/flux-dev-panorama-lora-2:replicate",
      "Shakker-Labs/FLUX.1-dev-LoRA-add-details",
      "Shakker-Labs/FLUX.1-dev-LoRA-add-details:fal-ai",
      "Shakker-Labs/FLUX.1-dev-LoRA-add-details:replicate",
      "prithivMLmods/Canopus-Clothing-Flux-LoRA",
      "prithivMLmods/Canopus-Clothing-Flux-LoRA:fal-ai",
      "prithivMLmods/Canopus-Clothing-Flux-LoRA:replicate",
      "dvyio/flux-lora-art-nouveau",
      "dvyio/flux-lora-art-nouveau:fal-ai",
      "dvyio/flux-lora-art-nouveau:replicate",
      "playboy40k/flux-SadieSinkLora",
      "playboy40k/flux-SadieSinkLora:fal-ai",
      "playboy40k/flux-SadieSinkLora:replicate",
      "stabilityai/stable-diffusion-3.5-large-turbo",
      "stabilityai/stable-diffusion-3.5-large-turbo:fal-ai",
      "Keltezaa/scarlett-johansson-2003-flux",
      "Keltezaa/scarlett-johansson-2003-flux:fal-ai",
      "Keltezaa/scarlett-johansson-2003-flux:replicate",
      "Keltezaa/hanni-makina-flux",
      "Keltezaa/hanni-makina-flux:fal-ai",
      "Keltezaa/hanni-makina-flux:replicate",
      "prithivMLmods/Castor-3D-Sketchfab-Flux-LoRA",
      "prithivMLmods/Castor-3D-Sketchfab-Flux-LoRA:fal-ai",
      "prithivMLmods/Castor-3D-Sketchfab-Flux-LoRA:replicate",
      "xey/sldr_flux_nsfw_v2-studio",
      "xey/sldr_flux_nsfw_v2-studio:fal-ai",
      "xey/sldr_flux_nsfw_v2-studio:replicate",
      "prithivMLmods/Logo-Design-Flux-LoRA",
      "prithivMLmods/Logo-Design-Flux-LoRA:fal-ai",
      "prithivMLmods/Logo-Design-Flux-LoRA:replicate",
      "prithivMLmods/Seamless-Pattern-Design-Flux-LoRA",
      "prithivMLmods/Seamless-Pattern-Design-Flux-LoRA:fal-ai",
      "prithivMLmods/Seamless-Pattern-Design-Flux-LoRA:replicate",
      "SedatAl/Interior-Flux-Lora",
      "SedatAl/Interior-Flux-Lora:fal-ai",
      "SedatAl/Interior-Flux-Lora:replicate",
      "strangerzonehf/Flux-Sketch-Smudge-LoRA",
      "strangerzonehf/Flux-Sketch-Smudge-LoRA:fal-ai",
      "strangerzonehf/Flux-Sketch-Smudge-LoRA:replicate",
      "AiWise/Juggernaut-XL-V9-GE-RDPhoto2-Lightning_4S",
      "AiWise/Juggernaut-XL-V9-GE-RDPhoto2-Lightning_4S:fal-ai",
      "blurgy/CoMPaSS-FLUX.1",
      "blurgy/CoMPaSS-FLUX.1:fal-ai",
      "blurgy/CoMPaSS-FLUX.1:replicate",
      "razor7x/sdxl-base-1.0-interior-myspace-lora",
      "razor7x/sdxl-base-1.0-interior-myspace-lora:fal-ai",
      "miaaiart/flower-beauty-10",
      "miaaiart/flower-beauty-10:fal-ai",
      "miaaiart/flower-beauty-10:replicate",
      "HiDream-ai/HiDream-I1-Fast",
      "HiDream-ai/HiDream-I1-Fast:fal-ai",
      "Viktor1717/scandinavian-interior-style1",
      "Viktor1717/scandinavian-interior-style1:fal-ai",
      "Viktor1717/scandinavian-interior-style1:replicate",
      "RedbeardNZ/Flux.1-Dev-LoRA-HDR-Realism",
      "RedbeardNZ/Flux.1-Dev-LoRA-HDR-Realism:fal-ai",
      "RedbeardNZ/Flux.1-Dev-LoRA-HDR-Realism:replicate",
      "treeshark/feedbaxv3.safetensors",
      "treeshark/feedbaxv3.safetensors:fal-ai",
      "treeshark/feedbaxv3.safetensors:replicate",
      "TheRaf7/ultra-real-wan2.2",
      "TheRaf7/ultra-real-wan2.2:fal-ai",
      "starsfriday/Qwen-Image-NSFW",
      "starsfriday/Qwen-Image-NSFW:fal-ai",
      "prithivMLmods/Qwen-Image-Anime-LoRA",
      "prithivMLmods/Qwen-Image-Anime-LoRA:fal-ai",
      "Raelina/Raena-Qwen-Image",
      "Raelina/Raena-Qwen-Image:fal-ai",
      "Daverrrr75/Qwen-Lora-Lenovo-Ultrareal",
      "Daverrrr75/Qwen-Lora-Lenovo-Ultrareal:fal-ai",
      "Pinguin/qwen-edit-lora-remove-stuff",
      "Pinguin/qwen-edit-lora-remove-stuff:fal-ai",
      "ostris/qwen_image_detail_slider",
      "ostris/qwen_image_detail_slider:fal-ai",
      "renderartist/technically-color-qwen",
      "renderartist/technically-color-qwen:fal-ai",
      "PeterKocsis/IntrinsiX",
      "PeterKocsis/IntrinsiX:fal-ai",
      "PeterKocsis/IntrinsiX:replicate",
      "lichorosario/dott-qwen-image-lora",
      "lichorosario/dott-qwen-image-lora:fal-ai",
      "lichorosario/piccoli-abstracto-lora",
      "lichorosario/piccoli-abstracto-lora:fal-ai",
      "tanzim1/Elara-lora",
      "tanzim1/Elara-lora:fal-ai",
      "lichorosario/panorama-qwen-image-lora",
      "lichorosario/panorama-qwen-image-lora:fal-ai",
      "rockerBOO/flux.1-dev-SRPO-LoRA",
      "rockerBOO/flux.1-dev-SRPO-LoRA:fal-ai",
      "rockerBOO/flux.1-dev-SRPO-LoRA:replicate",
      "CultriX/flux-nsfw-highress",
      "CultriX/flux-nsfw-highress:fal-ai",
      "CultriX/flux-nsfw-highress:replicate",
      "enhanceaiteam/Flux-uncensored",
      "enhanceaiteam/Flux-uncensored:fal-ai",
      "enhanceaiteam/Flux-uncensored:replicate",
      "lustlyai/Flux_Lustly.ai_Uncensored_nsfw_v1",
      "lustlyai/Flux_Lustly.ai_Uncensored_nsfw_v1:fal-ai",
      "lustlyai/Flux_Lustly.ai_Uncensored_nsfw_v1:replicate",
      "Keltezaa/pfbk_inni_pussy_FLUX",
      "Keltezaa/pfbk_inni_pussy_FLUX:fal-ai",
      "Keltezaa/pfbk_inni_pussy_FLUX:replicate",
      "Keltezaa/NSFW_MASTER_FLUX",
      "Keltezaa/NSFW_MASTER_FLUX:fal-ai",
      "Keltezaa/NSFW_MASTER_FLUX:replicate",
      "kp-forks/Flux-uncensored",
      "kp-forks/Flux-uncensored:fal-ai",
      "kp-forks/Flux-uncensored:replicate"
    ],
    "model_count": 229
  },
  "HuggingSpace": {
    "provider_info": {
      "id": "HuggingSpace",
      "object": "provider",
      "created": 0,
      "url": "https://huggingface.co/spaces",
      "label": null
    },
    "models": [
      "command-a",
      "command-a-03-2025",
      "command-r",
      "command-r-08-2024",
      "command-r-plus",
      "command-r-plus-08-2024",
      "command-r7b",
      "command-r7b-12-2024",
      "command-r7b-arabic-02-2025",
      "flux",
      "flux-dev",
      "flux-kontext-dev",
      "janus-pro-7b",
      "janus-pro-7b-image",
      "phi-4",
      "phi-4-multimodal",
      "qwen-2-72b",
      "qwen-2.5",
      "qwen-2.5-1m",
      "qwen-2.5-max",
      "qwen-3-0.6b",
      "qwen-3-1.7b",
      "qwen-3-14b",
      "qwen-3-235b",
      "qwen-3-30b",
      "qwen-3-30b-a3b",
      "qwen-3-32b",
      "qwen-3-4b",
      "qwen-3-8b",
      "sd-3.5-large"
    ],
    "model_count": 30
  },
  "LMArena": {
    "provider_info": {
      "id": "LMArena",
      "object": "provider",
      "created": 0,
      "url": "https://lmarena.ai",
      "label": "LMArena"
    },
    "models": [
      "qwen3-max-preview",
      "gpt-5-chat",
      "claude-opus-4-20250514",
      "gemini-2.5-pro",
      "gpt-5-high",
      "o3-2025-04-16",
      "gemini-2.5-flash",
      "chatgpt-4o-latest-20250326",
      "gemini-2.0-flash-001",
      "claude-3-5-sonnet-20241022",
      "llama-4-scout-17b-16e-instruct",
      "llama-4-maverick-03-26-experimental",
      "gpt-4.1-2025-04-14",
      "qwq-32b",
      "mistral-small-3.1-24b-instruct-2503",
      "gemma-3-27b-it",
      "x1-1-preview-0915",
      "command-a-03-2025",
      "gpt-4.1-mini-2025-04-14",
      "amazon.nova-pro-v1:0",
      "o3-mini",
      "grok-3-mini-beta",
      "kimi-k2-0905-preview",
      "o4-mini-2025-04-16",
      "gemini-2.5-flash-lite-preview-06-17-thinking",
      "amazon-nova-experimental-chat-05-14",
      "claude-3-7-sonnet-20250219-thinking-32k",
      "claude-3-5-haiku-20241022",
      "mistral-medium-2505",
      "deepseek-v3-0324",
      "magistral-medium-2506",
      "EB45-turbo-vl-0906",
      "claude-sonnet-4-20250514",
      "llama-4-maverick-17b-128e-instruct",
      "qwen3-30b-a3b",
      "stephen-v2",
      "qwen3-235b-a22b",
      "llama-3.3-70b-instruct",
      "x1-turbo-0906",
      "qwen3-30b-a3b-instruct-2507",
      "claude-3-7-sonnet-20250219",
      "minimax-m1",
      "claude-sonnet-4-20250514-thinking-32k",
      "qwen3-235b-a22b-no-thinking",
      "claude-opus-4-20250514-thinking-16k",
      "stephen-vision-csfix",
      "mistral-small-2506",
      "grok-3-mini-high",
      "grok-4-0709",
      "glm-4.5",
      "kimi-k2-0711-preview",
      "Bailing-Lite-250220",
      "gpt-oss-20b",
      "claude-opus-4-1-20250805",
      "gemini-2.5-pro-grounding-exp",
      "qwen-vl-max-2025-08-13",
      "gpt-oss-120b",
      "qwen3-235b-a22b-instruct-2507",
      "step-3",
      "nightride-on",
      "EB45-vision",
      "nightride-on-v2",
      "qwen3-coder-480b-a35b-instruct",
      "qwen3-235b-a22b-thinking-2507",
      "glm-4.5-air",
      "mistral-medium-2508",
      "seedream-4-high-res",
      "lmarena-internal-test-only",
      "deepseek-v3.1",
      "not-a-new-model",
      "gpt-5-mini-high",
      "deepseek-v3.1-thinking",
      "claude-opus-4-1-20250805-thinking-16k",
      "EB45-turbo",
      "glm-4.5v",
      "gpt-5-nano-high",
      "redwood",
      "sorting-hat",
      "gpt-5-high-new-system-prompt",
      "leepwal",
      "route66",
      "mai-1-preview",
      "oceanreef",
      "phantom-0903-4",
      "anonymous-925",
      "qwen3-next-80b-a3b-instruct",
      "qwen3-next-80b-a3b-thinking",
      "longcat-flash-chat",
      "oceanstone",
      "raptor",
      "gemini-2.5-flash-image-preview (nano-banana)",
      "imagen-4.0-generate-preview-06-06",
      "flux-1-kontext-dev",
      "imagen-3.0-generate-002",
      "recraft-v3",
      "photon",
      "dall-e-3",
      "gpt-image-1-high-fidelity",
      "lucid-origin",
      "gpt-image-1",
      "flux-1-kontext-pro",
      "imagen-4.0-ultra-generate-preview-06-06",
      "gemini-2.0-flash-preview-image-generation",
      "qwen-image-prompt-extend",
      "seedream-4-high-res",
      "ideogram-v3-quality",
      "seedream-3",
      "flux-1-kontext-max",
      "qwen-image-edit",
      "seededit-3.0",
      "hunyuan-image-2.1",
      "hidream-e1.1"
    ],
    "model_count": 112
  },
  "LambdaChat": {
    "provider_info": {
      "id": "LambdaChat",
      "object": "provider",
      "created": 0,
      "url": "https://lambda.chat",
      "label": "Lambda Chat"
    },
    "models": [
      "deepseek-llama3.3-70b",
      "apriel-5b-instruct",
      "hermes-3-llama-3.1-405b-fp8",
      "llama3.3-70b-instruct-fp8",
      "llama3.3-70b-instruct-fp8",
      "qwen3-32b-fp8"
    ],
    "model_count": 6
  },
  "MarkItDown": {
    "provider_info": {
      "id": "MarkItDown",
      "object": "provider",
      "created": 0,
      "url": null,
      "label": null
    },
    "models": [],
    "model_count": 0
  },
  "MetaAI": {
    "provider_info": {
      "id": "MetaAI",
      "object": "provider",
      "created": 0,
      "url": "https://www.meta.ai",
      "label": "Meta AI"
    },
    "models": [
      "meta-ai"
    ],
    "model_count": 1
  },
  "MetaAIAccount": {
    "provider_info": {
      "id": "MetaAIAccount",
      "object": "provider",
      "created": 0,
      "url": "https://www.meta.ai",
      "label": "Meta AI"
    },
    "models": [
      "meta-ai"
    ],
    "model_count": 1
  },
  "MicrosoftDesigner": {
    "provider_info": {
      "id": "MicrosoftDesigner",
      "object": "provider",
      "created": 0,
      "url": "https://designer.microsoft.com",
      "label": "Microsoft Designer"
    },
    "models": [
      "dall-e-3",
      "1024x1024",
      "1024x1792",
      "1792x1024"
    ],
    "model_count": 4
  },
  "Microsoft_Phi_4_Multimodal": {
    "provider_info": {
      "id": "Microsoft_Phi_4_Multimodal",
      "object": "provider",
      "created": 0,
      "url": "https://huggingface.co/spaces/microsoft/phi-4-multimodal",
      "label": "Microsoft Phi-4"
    },
    "models": [
      "phi-4-multimodal"
    ],
    "model_count": 1
  },
  "MiniMax": {
    "provider_info": {
      "id": "MiniMax",
      "object": "provider",
      "created": 0,
      "url": "https://www.hailuo.ai/chat",
      "label": "MiniMax API"
    },
    "models": [
      "MiniMax-Text-01",
      "abab6.5s-chat"
    ],
    "model_count": 2
  },
  "Mintlify": {
    "provider_info": {
      "id": "Mintlify",
      "object": "provider",
      "created": 0,
      "url": "https://mintlify.com",
      "label": "Mintlify"
    },
    "models": [
      "mintlify"
    ],
    "model_count": 1
  },
  "Nvidia": {
    "provider_info": {
      "id": "Nvidia",
      "object": "provider",
      "created": 0,
      "url": "https://build.nvidia.com",
      "label": "Nvidia"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/Nvidia/models"
  },
  "OIVSCodeSer0501": {
    "provider_info": {
      "id": "OIVSCodeSer0501",
      "object": "provider",
      "created": 0,
      "url": "https://oi-vscode-server-0501.onrender.com",
      "label": "OI VSCode Server 0501"
    },
    "models": [
      "custom/blackbox-base",
      "gpt-4.1-mini",
      "x-ai/grok-4-fast:free"
    ],
    "model_count": 3
  },
  "OIVSCodeSer2": {
    "provider_info": {
      "id": "OIVSCodeSer2",
      "object": "provider",
      "created": 0,
      "url": "https://oi-vscode-server-2.onrender.com",
      "label": "OI VSCode Server 2"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/OIVSCodeSer2/models"
  },
  "Ollama": {
    "provider_info": {
      "id": "Ollama",
      "object": "provider",
      "created": 0,
      "url": "https://ollama.com",
      "label": "Ollama ü¶ô"
    },
    "models": [],
    "model_count": 0
  },
  "OpenAIFM": {
    "provider_info": {
      "id": "OpenAIFM",
      "object": "provider",
      "created": 0,
      "url": "https://www.openai.fm",
      "label": "OpenAI.fm"
    },
    "models": [
      "friendly",
      "patient_teacher",
      "noir_detective",
      "cowboy",
      "calm",
      "scientific_style",
      "alloy",
      "ash",
      "ballad",
      "coral",
      "echo",
      "fable",
      "onyx",
      "nova",
      "sage",
      "shimmer",
      "verse"
    ],
    "model_count": 17
  },
  "OpenRouter": {
    "provider_info": {
      "id": "OpenRouter",
      "object": "provider",
      "created": 0,
      "url": "https://openrouter.ai",
      "label": "OpenRouter"
    },
    "models": [
      "agentica-org/deepcoder-14b-preview",
      "agentica-org/deepcoder-14b-preview:free",
      "ai21/jamba-large-1.7",
      "ai21/jamba-mini-1.7",
      "aion-labs/aion-1.0",
      "aion-labs/aion-1.0-mini",
      "aion-labs/aion-rp-llama-3.1-8b",
      "alfredpros/codellama-7b-instruct-solidity",
      "alibaba/tongyi-deepresearch-30b-a3b",
      "alibaba/tongyi-deepresearch-30b-a3b:free",
      "allenai/molmo-7b-d",
      "allenai/olmo-2-0325-32b-instruct",
      "alpindale/goliath-120b",
      "amazon/nova-lite-v1",
      "amazon/nova-micro-v1",
      "amazon/nova-pro-v1",
      "anthracite-org/magnum-v2-72b",
      "anthracite-org/magnum-v4-72b",
      "anthropic/claude-3-haiku",
      "anthropic/claude-3-opus",
      "anthropic/claude-3.5-haiku",
      "anthropic/claude-3.5-haiku-20241022",
      "anthropic/claude-3.5-sonnet",
      "anthropic/claude-3.5-sonnet-20240620",
      "anthropic/claude-3.7-sonnet",
      "anthropic/claude-3.7-sonnet:thinking",
      "anthropic/claude-haiku-4.5",
      "anthropic/claude-opus-4",
      "anthropic/claude-opus-4.1",
      "anthropic/claude-sonnet-4",
      "anthropic/claude-sonnet-4.5",
      "arcee-ai/afm-4.5b",
      "arcee-ai/coder-large",
      "arcee-ai/maestro-reasoning",
      "arcee-ai/spotlight",
      "arcee-ai/virtuoso-large",
      "arliai/qwq-32b-arliai-rpr-v1",
      "arliai/qwq-32b-arliai-rpr-v1:free",
      "baidu/ernie-4.5-21b-a3b",
      "baidu/ernie-4.5-21b-a3b-thinking",
      "baidu/ernie-4.5-300b-a47b",
      "baidu/ernie-4.5-vl-28b-a3b",
      "baidu/ernie-4.5-vl-424b-a47b",
      "bytedance/ui-tars-1.5-7b",
      "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
      "cognitivecomputations/dolphin3.0-mistral-24b",
      "cognitivecomputations/dolphin3.0-mistral-24b:free",
      "cohere/command-a",
      "cohere/command-r-08-2024",
      "cohere/command-r-plus-08-2024",
      "cohere/command-r7b-12-2024",
      "deepcogito/cogito-v2-preview-deepseek-671b",
      "deepcogito/cogito-v2-preview-llama-109b-moe",
      "deepcogito/cogito-v2-preview-llama-405b",
      "deepcogito/cogito-v2-preview-llama-70b",
      "deepseek/deepseek-chat",
      "deepseek/deepseek-chat-v3-0324",
      "deepseek/deepseek-chat-v3-0324:free",
      "deepseek/deepseek-chat-v3.1",
      "deepseek/deepseek-chat-v3.1:free",
      "deepseek/deepseek-prover-v2",
      "deepseek/deepseek-r1",
      "deepseek/deepseek-r1-0528",
      "deepseek/deepseek-r1-0528-qwen3-8b",
      "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "deepseek/deepseek-r1-0528:free",
      "deepseek/deepseek-r1-distill-llama-70b",
      "deepseek/deepseek-r1-distill-llama-70b:free",
      "deepseek/deepseek-r1-distill-qwen-14b",
      "deepseek/deepseek-r1-distill-qwen-32b",
      "deepseek/deepseek-r1:free",
      "deepseek/deepseek-v3.1-terminus",
      "deepseek/deepseek-v3.2-exp",
      "eleutherai/llemma_7b",
      "google/gemini-2.0-flash-001",
      "google/gemini-2.0-flash-exp:free",
      "google/gemini-2.0-flash-lite-001",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-flash-image",
      "google/gemini-2.5-flash-image-preview",
      "google/gemini-2.5-flash-lite",
      "google/gemini-2.5-flash-lite-preview-06-17",
      "google/gemini-2.5-flash-lite-preview-09-2025",
      "google/gemini-2.5-flash-preview-09-2025",
      "google/gemini-2.5-pro",
      "google/gemini-2.5-pro-preview",
      "google/gemini-2.5-pro-preview-05-06",
      "google/gemma-2-27b-it",
      "google/gemma-2-9b-it",
      "google/gemma-2-9b-it:free",
      "google/gemma-3-12b-it",
      "google/gemma-3-12b-it:free",
      "google/gemma-3-27b-it",
      "google/gemma-3-27b-it:free",
      "google/gemma-3-4b-it",
      "google/gemma-3-4b-it:free",
      "google/gemma-3n-e2b-it:free",
      "google/gemma-3n-e4b-it",
      "google/gemma-3n-e4b-it:free",
      "gryphe/mythomax-l2-13b",
      "inception/mercury",
      "inception/mercury-coder",
      "inclusionai/ling-1t",
      "inclusionai/ring-1t",
      "inflection/inflection-3-pi",
      "inflection/inflection-3-productivity",
      "liquid/lfm-3b",
      "liquid/lfm-7b",
      "mancer/weaver",
      "meituan/longcat-flash-chat",
      "meituan/longcat-flash-chat:free",
      "meta-llama/llama-3-70b-instruct",
      "meta-llama/llama-3-8b-instruct",
      "meta-llama/llama-3.1-405b",
      "meta-llama/llama-3.1-405b-instruct",
      "meta-llama/llama-3.1-70b-instruct",
      "meta-llama/llama-3.1-8b-instruct",
      "meta-llama/llama-3.2-11b-vision-instruct",
      "meta-llama/llama-3.2-1b-instruct",
      "meta-llama/llama-3.2-3b-instruct",
      "meta-llama/llama-3.2-3b-instruct:free",
      "meta-llama/llama-3.2-90b-vision-instruct",
      "meta-llama/llama-3.3-70b-instruct",
      "meta-llama/llama-3.3-70b-instruct:free",
      "meta-llama/llama-3.3-8b-instruct:free",
      "meta-llama/llama-4-maverick",
      "meta-llama/llama-4-maverick:free",
      "meta-llama/llama-4-scout",
      "meta-llama/llama-4-scout:free",
      "meta-llama/llama-guard-2-8b",
      "meta-llama/llama-guard-3-8b",
      "meta-llama/llama-guard-4-12b",
      "microsoft/mai-ds-r1",
      "microsoft/mai-ds-r1:free",
      "microsoft/phi-3-medium-128k-instruct",
      "microsoft/phi-3-mini-128k-instruct",
      "microsoft/phi-3.5-mini-128k-instruct",
      "microsoft/phi-4",
      "microsoft/phi-4-multimodal-instruct",
      "microsoft/phi-4-reasoning-plus",
      "microsoft/wizardlm-2-8x22b",
      "minimax/minimax-01",
      "minimax/minimax-m1",
      "mistralai/codestral-2501",
      "mistralai/codestral-2508",
      "mistralai/devstral-medium",
      "mistralai/devstral-small",
      "mistralai/devstral-small-2505",
      "mistralai/devstral-small-2505:free",
      "mistralai/magistral-medium-2506",
      "mistralai/magistral-medium-2506:thinking",
      "mistralai/magistral-small-2506",
      "mistralai/ministral-3b",
      "mistralai/ministral-8b",
      "mistralai/mistral-7b-instruct",
      "mistralai/mistral-7b-instruct-v0.1",
      "mistralai/mistral-7b-instruct-v0.2",
      "mistralai/mistral-7b-instruct-v0.3",
      "mistralai/mistral-7b-instruct:free",
      "mistralai/mistral-large",
      "mistralai/mistral-large-2407",
      "mistralai/mistral-large-2411",
      "mistralai/mistral-medium-3",
      "mistralai/mistral-medium-3.1",
      "mistralai/mistral-nemo",
      "mistralai/mistral-nemo:free",
      "mistralai/mistral-saba",
      "mistralai/mistral-small",
      "mistralai/mistral-small-24b-instruct-2501",
      "mistralai/mistral-small-24b-instruct-2501:free",
      "mistralai/mistral-small-3.1-24b-instruct",
      "mistralai/mistral-small-3.1-24b-instruct:free",
      "mistralai/mistral-small-3.2-24b-instruct",
      "mistralai/mistral-small-3.2-24b-instruct:free",
      "mistralai/mistral-tiny",
      "mistralai/mixtral-8x22b-instruct",
      "mistralai/mixtral-8x7b-instruct",
      "mistralai/pixtral-12b",
      "mistralai/pixtral-large-2411",
      "moonshotai/kimi-dev-72b",
      "moonshotai/kimi-dev-72b:free",
      "moonshotai/kimi-k2",
      "moonshotai/kimi-k2-0905",
      "moonshotai/kimi-k2:free",
      "morph/morph-v3-fast",
      "morph/morph-v3-large",
      "neversleep/llama-3.1-lumimaid-8b",
      "neversleep/noromaid-20b",
      "nousresearch/deephermes-3-llama-3-8b-preview",
      "nousresearch/deephermes-3-llama-3-8b-preview:free",
      "nousresearch/deephermes-3-mistral-24b-preview",
      "nousresearch/hermes-2-pro-llama-3-8b",
      "nousresearch/hermes-3-llama-3.1-405b",
      "nousresearch/hermes-3-llama-3.1-70b",
      "nousresearch/hermes-4-405b",
      "nousresearch/hermes-4-70b",
      "nvidia/llama-3.1-nemotron-70b-instruct",
      "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "nvidia/llama-3.3-nemotron-super-49b-v1.5",
      "nvidia/nemotron-nano-9b-v2",
      "nvidia/nemotron-nano-9b-v2:free",
      "openai/chatgpt-4o-latest",
      "openai/codex-mini",
      "openai/gpt-3.5-turbo",
      "openai/gpt-3.5-turbo-0613",
      "openai/gpt-3.5-turbo-16k",
      "openai/gpt-3.5-turbo-instruct",
      "openai/gpt-4",
      "openai/gpt-4-0314",
      "openai/gpt-4-1106-preview",
      "openai/gpt-4-turbo",
      "openai/gpt-4-turbo-preview",
      "openai/gpt-4.1",
      "openai/gpt-4.1-mini",
      "openai/gpt-4.1-nano",
      "openai/gpt-4o",
      "openai/gpt-4o-2024-05-13",
      "openai/gpt-4o-2024-08-06",
      "openai/gpt-4o-2024-11-20",
      "openai/gpt-4o-audio-preview",
      "openai/gpt-4o-mini",
      "openai/gpt-4o-mini-2024-07-18",
      "openai/gpt-4o-mini-search-preview",
      "openai/gpt-4o-search-preview",
      "openai/gpt-4o:extended",
      "openai/gpt-5",
      "openai/gpt-5-chat",
      "openai/gpt-5-codex",
      "openai/gpt-5-image",
      "openai/gpt-5-image-mini",
      "openai/gpt-5-mini",
      "openai/gpt-5-nano",
      "openai/gpt-5-pro",
      "openai/gpt-oss-120b",
      "openai/gpt-oss-20b",
      "openai/gpt-oss-20b:free",
      "openai/o1",
      "openai/o1-mini",
      "openai/o1-mini-2024-09-12",
      "openai/o1-pro",
      "openai/o3",
      "openai/o3-deep-research",
      "openai/o3-mini",
      "openai/o3-mini-high",
      "openai/o3-pro",
      "openai/o4-mini",
      "openai/o4-mini-deep-research",
      "openai/o4-mini-high",
      "opengvlab/internvl3-78b",
      "openrouter/auto",
      "perplexity/sonar",
      "perplexity/sonar-deep-research",
      "perplexity/sonar-pro",
      "perplexity/sonar-reasoning",
      "perplexity/sonar-reasoning-pro",
      "qwen/qwen-2.5-72b-instruct",
      "qwen/qwen-2.5-72b-instruct:free",
      "qwen/qwen-2.5-7b-instruct",
      "qwen/qwen-2.5-coder-32b-instruct",
      "qwen/qwen-2.5-coder-32b-instruct:free",
      "qwen/qwen-2.5-vl-7b-instruct",
      "qwen/qwen-max",
      "qwen/qwen-plus",
      "qwen/qwen-plus-2025-07-28",
      "qwen/qwen-plus-2025-07-28:thinking",
      "qwen/qwen-turbo",
      "qwen/qwen-vl-max",
      "qwen/qwen-vl-plus",
      "qwen/qwen2.5-coder-7b-instruct",
      "qwen/qwen2.5-vl-32b-instruct",
      "qwen/qwen2.5-vl-32b-instruct:free",
      "qwen/qwen2.5-vl-72b-instruct",
      "qwen/qwen2.5-vl-72b-instruct:free",
      "qwen/qwen3-14b",
      "qwen/qwen3-14b:free",
      "qwen/qwen3-235b-a22b",
      "qwen/qwen3-235b-a22b-2507",
      "qwen/qwen3-235b-a22b-thinking-2507",
      "qwen/qwen3-235b-a22b:free",
      "qwen/qwen3-30b-a3b",
      "qwen/qwen3-30b-a3b-instruct-2507",
      "qwen/qwen3-30b-a3b-thinking-2507",
      "qwen/qwen3-30b-a3b:free",
      "qwen/qwen3-32b",
      "qwen/qwen3-4b:free",
      "qwen/qwen3-8b",
      "qwen/qwen3-8b:free",
      "qwen/qwen3-coder",
      "qwen/qwen3-coder-30b-a3b-instruct",
      "qwen/qwen3-coder-flash",
      "qwen/qwen3-coder-plus",
      "qwen/qwen3-coder:free",
      "qwen/qwen3-max",
      "qwen/qwen3-next-80b-a3b-instruct",
      "qwen/qwen3-next-80b-a3b-thinking",
      "qwen/qwen3-vl-235b-a22b-instruct",
      "qwen/qwen3-vl-235b-a22b-thinking",
      "qwen/qwen3-vl-30b-a3b-instruct",
      "qwen/qwen3-vl-30b-a3b-thinking",
      "qwen/qwen3-vl-8b-instruct",
      "qwen/qwen3-vl-8b-thinking",
      "qwen/qwq-32b",
      "raifle/sorcererlm-8x22b",
      "relace/relace-apply-3",
      "sao10k/l3-euryale-70b",
      "sao10k/l3-lunaris-8b",
      "sao10k/l3.1-70b-hanami-x1",
      "sao10k/l3.1-euryale-70b",
      "sao10k/l3.3-euryale-70b",
      "shisa-ai/shisa-v2-llama3.3-70b",
      "shisa-ai/shisa-v2-llama3.3-70b:free",
      "stepfun-ai/step3",
      "switchpoint/router",
      "tencent/hunyuan-a13b-instruct",
      "tencent/hunyuan-a13b-instruct:free",
      "thedrummer/anubis-70b-v1.1",
      "thedrummer/cydonia-24b-v4.1",
      "thedrummer/rocinante-12b",
      "thedrummer/skyfall-36b-v2",
      "thedrummer/unslopnemo-12b",
      "thudm/glm-4.1v-9b-thinking",
      "thudm/glm-z1-32b",
      "tngtech/deepseek-r1t-chimera",
      "tngtech/deepseek-r1t-chimera:free",
      "tngtech/deepseek-r1t2-chimera",
      "tngtech/deepseek-r1t2-chimera:free",
      "undi95/remm-slerp-l2-13b",
      "x-ai/grok-3",
      "x-ai/grok-3-beta",
      "x-ai/grok-3-mini",
      "x-ai/grok-3-mini-beta",
      "x-ai/grok-4",
      "x-ai/grok-4-fast",
      "x-ai/grok-code-fast-1",
      "z-ai/glm-4-32b",
      "z-ai/glm-4.5",
      "z-ai/glm-4.5-air",
      "z-ai/glm-4.5-air:free",
      "z-ai/glm-4.5v",
      "z-ai/glm-4.6"
    ],
    "model_count": 340
  },
  "OpenRouterFree": {
    "provider_info": {
      "id": "OpenRouterFree",
      "object": "provider",
      "created": 0,
      "url": "https://openrouter.ai",
      "label": "OpenRouter (free)"
    },
    "models": [
      "agentica-org/deepcoder-14b-preview:free",
      "alibaba/tongyi-deepresearch-30b-a3b:free",
      "arliai/qwq-32b-arliai-rpr-v1:free",
      "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
      "cognitivecomputations/dolphin3.0-mistral-24b:free",
      "deepseek/deepseek-chat-v3-0324:free",
      "deepseek/deepseek-chat-v3.1:free",
      "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "deepseek/deepseek-r1-0528:free",
      "deepseek/deepseek-r1-distill-llama-70b:free",
      "deepseek/deepseek-r1:free",
      "google/gemini-2.0-flash-exp:free",
      "google/gemma-2-9b-it:free",
      "google/gemma-3-12b-it:free",
      "google/gemma-3-27b-it:free",
      "google/gemma-3-4b-it:free",
      "google/gemma-3n-e2b-it:free",
      "google/gemma-3n-e4b-it:free",
      "meituan/longcat-flash-chat:free",
      "meta-llama/llama-3.2-3b-instruct:free",
      "meta-llama/llama-3.3-70b-instruct:free",
      "meta-llama/llama-3.3-8b-instruct:free",
      "meta-llama/llama-4-maverick:free",
      "meta-llama/llama-4-scout:free",
      "microsoft/mai-ds-r1:free",
      "mistralai/devstral-small-2505:free",
      "mistralai/mistral-7b-instruct:free",
      "mistralai/mistral-nemo:free",
      "mistralai/mistral-small-24b-instruct-2501:free",
      "mistralai/mistral-small-3.1-24b-instruct:free",
      "mistralai/mistral-small-3.2-24b-instruct:free",
      "moonshotai/kimi-dev-72b:free",
      "moonshotai/kimi-k2:free",
      "nousresearch/deephermes-3-llama-3-8b-preview:free",
      "nvidia/nemotron-nano-9b-v2:free",
      "openai/gpt-oss-20b:free",
      "qwen/qwen-2.5-72b-instruct:free",
      "qwen/qwen-2.5-coder-32b-instruct:free",
      "qwen/qwen2.5-vl-32b-instruct:free",
      "qwen/qwen2.5-vl-72b-instruct:free",
      "qwen/qwen3-14b:free",
      "qwen/qwen3-235b-a22b:free",
      "qwen/qwen3-30b-a3b:free",
      "qwen/qwen3-4b:free",
      "qwen/qwen3-8b:free",
      "qwen/qwen3-coder:free",
      "shisa-ai/shisa-v2-llama3.3-70b:free",
      "tencent/hunyuan-a13b-instruct:free",
      "tngtech/deepseek-r1t-chimera:free",
      "tngtech/deepseek-r1t2-chimera:free",
      "z-ai/glm-4.5-air:free"
    ],
    "model_count": 51
  },
  "OpenaiAPI": {
    "provider_info": {
      "id": "OpenaiAPI",
      "object": "provider",
      "created": 0,
      "url": "https://platform.openai.com",
      "label": "OpenAI API"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/OpenaiAPI/models"
  },
  "OpenaiAccount": {
    "provider_info": {
      "id": "OpenaiAccount",
      "object": "provider",
      "created": 0,
      "url": "https://chatgpt.com",
      "label": "OpenAI ChatGPT"
    },
    "models": [
      "auto",
      "gpt-5",
      "gpt-5-instant",
      "gpt-5-thinking",
      "gpt-4",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.5",
      "gpt-4o",
      "gpt-4o-mini",
      "o1",
      "o1-mini",
      "o3-mini",
      "o3-mini-high",
      "o4-mini",
      "o4-mini-high",
      "gpt-image"
    ],
    "model_count": 17
  },
  "OpenaiChat": {
    "provider_info": {
      "id": "OpenaiChat",
      "object": "provider",
      "created": 0,
      "url": "https://chatgpt.com",
      "label": "OpenAI ChatGPT"
    },
    "models": [
      "auto",
      "gpt-5",
      "gpt-5-instant",
      "gpt-5-thinking",
      "gpt-4",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.5",
      "gpt-4o",
      "gpt-4o-mini",
      "o1",
      "o1-mini",
      "o3-mini",
      "o3-mini-high",
      "o4-mini",
      "o4-mini-high",
      "gpt-image"
    ],
    "model_count": 17
  },
  "OperaAria": {
    "provider_info": {
      "id": "OperaAria",
      "object": "provider",
      "created": 0,
      "url": "https://play.google.com/store/apps/details?id=com.opera.browser",
      "label": "Opera Aria"
    },
    "models": [
      "aria"
    ],
    "model_count": 1
  },
  "Perplexity": {
    "provider_info": {
      "id": "Perplexity",
      "object": "provider",
      "created": 0,
      "url": "https://www.perplexity.ai",
      "label": "Perplexity"
    },
    "models": [
      "auto",
      "turbo",
      "gpt41",
      "gpt5",
      "gpt5_thinking",
      "o3",
      "o3pro",
      "claude2",
      "claude37sonnetthinking",
      "claude40opus",
      "claude40opusthinking",
      "claude41opusthinking",
      "claude45sonnet",
      "claude45sonnetthinking",
      "experimental",
      "grok",
      "grok4",
      "gemini2flash",
      "pplx_pro",
      "pplx_pro_upgraded",
      "pplx_alpha",
      "pplx_beta",
      "comet_max_assistant",
      "o3_research",
      "o3pro_research",
      "claude40sonnet_research",
      "claude40sonnetthinking_research",
      "claude40opus_research",
      "claude40opusthinking_research",
      "o3_labs",
      "o3pro_labs",
      "claude40sonnetthinking_labs",
      "claude40opusthinking_labs",
      "o4mini",
      "o1",
      "gpt4o",
      "gpt45",
      "gpt4",
      "o3mini",
      "claude35haiku",
      "llama_x_large",
      "mistral",
      "claude3opus",
      "gemini",
      "pplx_reasoning",
      "r1"
    ],
    "model_count": 46
  },
  "PerplexityApi": {
    "provider_info": {
      "id": "PerplexityApi",
      "object": "provider",
      "created": 0,
      "url": "https://www.perplexity.ai",
      "label": "Perplexity API"
    },
    "models": [
      "llama-3-sonar-small-32k-chat",
      "llama-3-sonar-large-32k-online",
      "llama-3-sonar-large-32k-chat",
      "llama-3-sonar-large-32k-online",
      "llama-3-8b-instruct",
      "llama-3-70b-instruct"
    ],
    "model_count": 6
  },
  "Pi": {
    "provider_info": {
      "id": "Pi",
      "object": "provider",
      "created": 0,
      "url": "https://pi.ai/talk",
      "label": null
    },
    "models": [],
    "model_count": 0
  },
  "PollinationsAI": {
    "provider_info": {
      "id": "PollinationsAI",
      "object": "provider",
      "created": 0,
      "url": "https://pollinations.ai",
      "label": "Pollinations AI üå∏"
    },
    "models": [
      "openai",
      "evil",
      "deepseek-v3",
      "gemini-2.5-flash-lite",
      "searchgpt",
      "mistral-small-3.1-24b",
      "gpt-5-mini",
      "gpt-4o-mini-audio-preview",
      "gpt-5-nano",
      "gpt-5-chat",
      "o4-mini",
      "qwen-2.5-coder-32b",
      "llama-roblox",
      "bidara",
      "chickytutor",
      "midijourney",
      "rtist",
      "unity",
      "flux",
      "turbo",
      "kontext",
      "gptimage",
      "openai-audio",
      "alloy",
      "echo",
      "fable",
      "onyx",
      "nova",
      "shimmer",
      "coral",
      "verse",
      "ballad",
      "ash",
      "sage",
      "amuch",
      "dan"
    ],
    "model_count": 36
  },
  "PollinationsImage": {
    "provider_info": {
      "id": "PollinationsImage",
      "object": "provider",
      "created": 0,
      "url": "https://pollinations.ai",
      "label": "PollinationsImage"
    },
    "models": [
      "flux",
      "turbo",
      "kontext",
      "gptimage"
    ],
    "model_count": 4
  },
  "PuterJS": {
    "provider_info": {
      "id": "PuterJS",
      "object": "provider",
      "created": 0,
      "url": "https://docs.puter.com/playground",
      "label": "Puter.js"
    },
    "models": [
      "gpt-5-2025-08-07",
      "gpt-5",
      "gpt-5-mini-2025-08-07",
      "gpt-5-mini",
      "gpt-5-nano-2025-08-07",
      "gpt-5-nano",
      "gpt-5-chat-latest",
      "gpt-4o",
      "gpt-4o-mini",
      "o1",
      "o1-mini",
      "o1-pro",
      "o3",
      "o3-mini",
      "o4-mini",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.1-nano",
      "gpt-4.5-preview",
      "claude-sonnet-4-5-20250929",
      "claude-sonnet-4.5",
      "claude-sonnet-4-5",
      "claude-opus-4-1-20250805",
      "claude-opus-4-1",
      "claude-opus-4-20250514",
      "claude-opus-4",
      "claude-opus-4-latest",
      "claude-sonnet-4-20250514",
      "claude-sonnet-4",
      "claude-sonnet-4-latest",
      "claude-3-7-sonnet-20250219",
      "claude-3-7-sonnet-latest",
      "claude-3-5-sonnet-20241022",
      "claude-3-5-sonnet-latest",
      "claude-3-5-sonnet-20240620",
      "claude-3-haiku-20240307",
      "mistral-large-latest",
      "mistral-medium-2508",
      "mistral-medium-latest",
      "mistral-medium",
      "ministral-3b-2410",
      "ministral-3b-latest",
      "ministral-8b-2410",
      "ministral-8b-latest",
      "open-mistral-7b",
      "mistral-tiny",
      "mistral-tiny-2312",
      "open-mistral-nemo",
      "open-mistral-nemo-2407",
      "mistral-tiny-2407",
      "mistral-tiny-latest",
      "open-mixtral-8x7b",
      "mistral-small",
      "mistral-small-2312",
      "open-mixtral-8x22b",
      "open-mixtral-8x22b-2404",
      "pixtral-large-2411",
      "pixtral-large-latest",
      "mistral-large-pixtral-2411",
      "codestral-2508",
      "codestral-latest",
      "devstral-small-2507",
      "devstral-small-latest",
      "pixtral-12b-2409",
      "pixtral-12b",
      "pixtral-12b-latest",
      "mistral-small-2506",
      "mistral-small-latest",
      "magistral-medium-2509",
      "magistral-medium-latest",
      "magistral-small-2509",
      "magistral-small-latest",
      "mistral-moderation-2411",
      "mistral-moderation-latest",
      "mistral-ocr-2505",
      "mistral-ocr-latest",
      "grok-beta",
      "grok-vision-beta",
      "grok-3",
      "grok-3-fast",
      "grok-3-mini",
      "grok-3-mini-fast",
      "grok-2-vision",
      "grok-2",
      "deepseek-chat",
      "deepseek-reasoner",
      "gemini-1.5-flash",
      "gemini-2.0-flash",
      "mixtral-8x22b",
      "pixtral-large",
      "llama-2-70b",
      "llama-3-8b",
      "llama-3-70b",
      "llama-3.1-8b",
      "llama-3.1-70b",
      "llama-3.1-405b",
      "llama-3.2-1b",
      "llama-3.2-3b",
      "llama-3.2-11b",
      "llama-3.2-90b",
      "llama-3.3-8b",
      "llama-3.3-70b",
      "llama-4-maverick",
      "llama-4-scout",
      "gemini-1.5-8b-flash",
      "gemini-1.5-pro",
      "gemini-2.5-pro",
      "gemini-2.5-flash",
      "gemini-2.5-flash-thinking",
      "gemma-2-9b",
      "gemma-2-27b",
      "gemma-3-1b",
      "gemma-3-4b",
      "gemma-3-12b",
      "gemma-3-27b",
      "hermes-2-dpo",
      "hermes-2-pro",
      "hermes-3-70b",
      "hermes-3-405b",
      "deephermes-3-8b",
      "deephermes-3-24b",
      "phi-3-mini",
      "phi-3-medium",
      "phi-3.5-mini",
      "phi-4",
      "phi-4-multimodal",
      "phi-4-reasoning",
      "phi-4-reasoning-plus",
      "wizardlm-2-8x22b",
      "mai-ds-r1",
      "claude-3.7-sonnet",
      "claude-3.7-sonnet-thinking",
      "claude-3.5-haiku",
      "claude-3.5-sonnet",
      "claude-3-haiku",
      "claude-3-opus",
      "claude-3-sonnet",
      "claude-2.1",
      "claude-2",
      "claude-2.0",
      "reka-flash",
      "command-r7b",
      "command-r-plus",
      "command",
      "command-r",
      "command-a",
      "qwq-32b",
      "qwen-vl-plus",
      "qwen-vl-max",
      "qwen-turbo",
      "qwen-2.5-vl-72b",
      "qwen-plus",
      "qwen-max",
      "qwen-2.5-coder-32b",
      "qwen-2.5-7b",
      "qwen-2.5-72b",
      "qwen-2.5-vl-7b",
      "qwen-2-72b",
      "qwen-3-0.6b",
      "qwen-3-1.7b",
      "qwen-3-4b",
      "qwen-3-30b",
      "qwen-3-8b",
      "qwen-3-14b",
      "qwen-3-32b",
      "qwen-3-235b",
      "qwen-2.5-coder-7b",
      "qwen-2.5-vl-3b",
      "qwen-2.5-vl-32b",
      "deepseek-prover-v2",
      "deepseek-v3",
      "deepseek-v3-0324",
      "deepseek-r1-zero",
      "deepseek-r1-distill-llama-8b",
      "deepseek-r1-distill-qwen-1.5b",
      "deepseek-r1-distill-qwen-32b",
      "deepseek-r1-distill-qwen-14b",
      "deepseek-r1-distill-llama-70b",
      "deepseek-r1",
      "deepseek-coder",
      "inflection-3-productivity",
      "inflection-3-pi",
      "grok-3-beta",
      "grok",
      "sonar-reasoning-pro",
      "sonar-pro",
      "sonar-deep-research",
      "r1-1776",
      "sonar-reasoning",
      "sonar",
      "llama-3.1-sonar-small-online",
      "llama-3.1-sonar-large-online",
      "nemotron-49b",
      "nemotron-70b",
      "nemotron-253b",
      "glm-4",
      "glm-4-32b",
      "glm-z1-32b",
      "glm-4-9b",
      "glm-z1-9b",
      "glm-z1-rumination-32b",
      "minimax",
      "dolphin-3.0-r1-24b",
      "dolphin-3.0-24b",
      "dolphin-8x22b",
      "deepcoder-14b",
      "kimi-vl-thinking",
      "moonlight-16b",
      "qwerky-72b",
      "lfm-7b",
      "lfm-3b",
      "lfm-40b",
      "openrouter:deepcogito/cogito-v2-preview-llama-405b",
      "openrouter:openai/gpt-5-image-mini",
      "openrouter:anthropic/claude-haiku-4.5",
      "openrouter:qwen/qwen3-vl-8b-thinking",
      "openrouter:qwen/qwen3-vl-8b-instruct",
      "openrouter:openai/gpt-5-image",
      "openrouter:inclusionai/ring-1t",
      "openrouter:inclusionai/ling-1t",
      "openrouter:openai/o3-deep-research",
      "openrouter:openai/o4-mini-deep-research",
      "openrouter:nvidia/llama-3.3-nemotron-super-49b-v1.5",
      "openrouter:baidu/ernie-4.5-21b-a3b-thinking",
      "openrouter:google/gemini-2.5-flash-image",
      "openrouter:qwen/qwen3-vl-30b-a3b-thinking",
      "openrouter:qwen/qwen3-vl-30b-a3b-instruct",
      "openrouter:openai/gpt-5-pro",
      "openrouter:z-ai/glm-4.6",
      "openrouter:anthropic/claude-sonnet-4.5",
      "openrouter:deepseek/deepseek-v3.2-exp",
      "openrouter:thedrummer/cydonia-24b-v4.1",
      "openrouter:relace/relace-apply-3",
      "openrouter:google/gemini-2.5-flash-preview-09-2025",
      "openrouter:google/gemini-2.5-flash-lite-preview-09-2025",
      "openrouter:qwen/qwen3-vl-235b-a22b-thinking",
      "openrouter:qwen/qwen3-vl-235b-a22b-instruct",
      "openrouter:qwen/qwen3-max",
      "openrouter:qwen/qwen3-coder-plus",
      "openrouter:openai/gpt-5-codex",
      "openrouter:deepseek/deepseek-v3.1-terminus",
      "openrouter:x-ai/grok-4-fast",
      "openrouter:alibaba/tongyi-deepresearch-30b-a3b:free",
      "openrouter:alibaba/tongyi-deepresearch-30b-a3b",
      "openrouter:qwen/qwen3-coder-flash",
      "openrouter:arcee-ai/afm-4.5b",
      "openrouter:opengvlab/internvl3-78b",
      "openrouter:qwen/qwen3-next-80b-a3b-thinking",
      "openrouter:qwen/qwen3-next-80b-a3b-instruct",
      "openrouter:meituan/longcat-flash-chat:free",
      "openrouter:meituan/longcat-flash-chat",
      "openrouter:qwen/qwen-plus-2025-07-28",
      "openrouter:qwen/qwen-plus-2025-07-28:thinking",
      "openrouter:nvidia/nemotron-nano-9b-v2:free",
      "openrouter:nvidia/nemotron-nano-9b-v2",
      "openrouter:moonshotai/kimi-k2-0905",
      "openrouter:deepcogito/cogito-v2-preview-llama-70b",
      "openrouter:deepcogito/cogito-v2-preview-llama-109b-moe",
      "openrouter:deepcogito/cogito-v2-preview-deepseek-671b",
      "openrouter:stepfun-ai/step3",
      "openrouter:qwen/qwen3-30b-a3b-thinking-2507",
      "openrouter:x-ai/grok-code-fast-1",
      "openrouter:nousresearch/hermes-4-70b",
      "openrouter:nousresearch/hermes-4-405b",
      "openrouter:google/gemini-2.5-flash-image-preview",
      "openrouter:deepseek/deepseek-chat-v3.1:free",
      "openrouter:deepseek/deepseek-chat-v3.1",
      "openrouter:openai/gpt-4o-audio-preview",
      "openrouter:mistralai/mistral-medium-3.1",
      "openrouter:baidu/ernie-4.5-21b-a3b",
      "openrouter:baidu/ernie-4.5-vl-28b-a3b",
      "openrouter:z-ai/glm-4.5v",
      "openrouter:ai21/jamba-mini-1.7",
      "openrouter:ai21/jamba-large-1.7",
      "openrouter:openai/gpt-5-chat",
      "openrouter:openai/gpt-5",
      "openrouter:openai/gpt-5-mini",
      "openrouter:openai/gpt-5-nano",
      "openrouter:openai/gpt-oss-120b",
      "openrouter:openai/gpt-oss-20b:free",
      "openrouter:openai/gpt-oss-20b",
      "openrouter:anthropic/claude-opus-4.1",
      "openrouter:mistralai/codestral-2508",
      "openrouter:qwen/qwen3-coder-30b-a3b-instruct",
      "openrouter:qwen/qwen3-30b-a3b-instruct-2507",
      "openrouter:z-ai/glm-4.5",
      "openrouter:z-ai/glm-4.5-air:free",
      "openrouter:z-ai/glm-4.5-air",
      "openrouter:qwen/qwen3-235b-a22b-thinking-2507",
      "openrouter:z-ai/glm-4-32b",
      "openrouter:qwen/qwen3-coder:free",
      "openrouter:qwen/qwen3-coder",
      "openrouter:bytedance/ui-tars-1.5-7b",
      "openrouter:google/gemini-2.5-flash-lite",
      "openrouter:qwen/qwen3-235b-a22b-2507",
      "openrouter:switchpoint/router",
      "openrouter:moonshotai/kimi-k2:free",
      "openrouter:moonshotai/kimi-k2",
      "openrouter:thudm/glm-4.1v-9b-thinking",
      "openrouter:mistralai/devstral-medium",
      "openrouter:mistralai/devstral-small",
      "openrouter:cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
      "openrouter:x-ai/grok-4",
      "openrouter:google/gemma-3n-e2b-it:free",
      "openrouter:tencent/hunyuan-a13b-instruct:free",
      "openrouter:tencent/hunyuan-a13b-instruct",
      "openrouter:tngtech/deepseek-r1t2-chimera:free",
      "openrouter:tngtech/deepseek-r1t2-chimera",
      "openrouter:morph/morph-v3-large",
      "openrouter:morph/morph-v3-fast",
      "openrouter:baidu/ernie-4.5-vl-424b-a47b",
      "openrouter:baidu/ernie-4.5-300b-a47b",
      "openrouter:thedrummer/anubis-70b-v1.1",
      "openrouter:inception/mercury",
      "openrouter:mistralai/mistral-small-3.2-24b-instruct:free",
      "openrouter:mistralai/mistral-small-3.2-24b-instruct",
      "openrouter:minimax/minimax-m1",
      "openrouter:google/gemini-2.5-flash-lite-preview-06-17",
      "openrouter:google/gemini-2.5-flash",
      "openrouter:google/gemini-2.5-pro",
      "openrouter:moonshotai/kimi-dev-72b:free",
      "openrouter:moonshotai/kimi-dev-72b",
      "openrouter:openai/o3-pro",
      "openrouter:x-ai/grok-3-mini",
      "openrouter:x-ai/grok-3",
      "openrouter:mistralai/magistral-small-2506",
      "openrouter:mistralai/magistral-medium-2506:thinking",
      "openrouter:mistralai/magistral-medium-2506",
      "openrouter:google/gemini-2.5-pro-preview",
      "openrouter:deepseek/deepseek-r1-0528-qwen3-8b:free",
      "openrouter:deepseek/deepseek-r1-0528-qwen3-8b",
      "openrouter:deepseek/deepseek-r1-0528:free",
      "openrouter:deepseek/deepseek-r1-0528",
      "openrouter:anthropic/claude-opus-4",
      "openrouter:anthropic/claude-sonnet-4",
      "openrouter:mistralai/devstral-small-2505:free",
      "openrouter:mistralai/devstral-small-2505",
      "openrouter:google/gemma-3n-e4b-it:free",
      "openrouter:google/gemma-3n-e4b-it",
      "openrouter:openai/codex-mini",
      "openrouter:meta-llama/llama-3.3-8b-instruct:free",
      "openrouter:nousresearch/deephermes-3-mistral-24b-preview",
      "openrouter:mistralai/mistral-medium-3",
      "openrouter:google/gemini-2.5-pro-preview-05-06",
      "openrouter:arcee-ai/spotlight",
      "openrouter:arcee-ai/maestro-reasoning",
      "openrouter:arcee-ai/virtuoso-large",
      "openrouter:arcee-ai/coder-large",
      "openrouter:microsoft/phi-4-reasoning-plus",
      "openrouter:inception/mercury-coder",
      "openrouter:qwen/qwen3-4b:free",
      "openrouter:deepseek/deepseek-prover-v2",
      "openrouter:meta-llama/llama-guard-4-12b",
      "openrouter:qwen/qwen3-30b-a3b:free",
      "openrouter:qwen/qwen3-30b-a3b",
      "openrouter:qwen/qwen3-8b:free",
      "openrouter:qwen/qwen3-8b",
      "openrouter:qwen/qwen3-14b:free",
      "openrouter:qwen/qwen3-14b",
      "openrouter:qwen/qwen3-32b",
      "openrouter:qwen/qwen3-235b-a22b:free",
      "openrouter:qwen/qwen3-235b-a22b",
      "openrouter:tngtech/deepseek-r1t-chimera:free",
      "openrouter:tngtech/deepseek-r1t-chimera",
      "openrouter:microsoft/mai-ds-r1:free",
      "openrouter:microsoft/mai-ds-r1",
      "openrouter:thudm/glm-z1-32b",
      "openrouter:openai/o4-mini-high",
      "openrouter:openai/o3",
      "openrouter:openai/o4-mini",
      "openrouter:shisa-ai/shisa-v2-llama3.3-70b:free",
      "openrouter:shisa-ai/shisa-v2-llama3.3-70b",
      "openrouter:qwen/qwen2.5-coder-7b-instruct",
      "openrouter:openai/gpt-4.1",
      "openrouter:openai/gpt-4.1-mini",
      "openrouter:openai/gpt-4.1-nano",
      "openrouter:eleutherai/llemma_7b",
      "openrouter:alfredpros/codellama-7b-instruct-solidity",
      "openrouter:arliai/qwq-32b-arliai-rpr-v1:free",
      "openrouter:arliai/qwq-32b-arliai-rpr-v1",
      "openrouter:agentica-org/deepcoder-14b-preview:free",
      "openrouter:agentica-org/deepcoder-14b-preview",
      "openrouter:x-ai/grok-3-mini-beta",
      "openrouter:x-ai/grok-3-beta",
      "openrouter:nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "openrouter:meta-llama/llama-4-maverick:free",
      "openrouter:meta-llama/llama-4-maverick",
      "openrouter:meta-llama/llama-4-scout:free",
      "openrouter:meta-llama/llama-4-scout",
      "openrouter:allenai/molmo-7b-d",
      "openrouter:qwen/qwen2.5-vl-32b-instruct:free",
      "openrouter:qwen/qwen2.5-vl-32b-instruct",
      "openrouter:deepseek/deepseek-chat-v3-0324:free",
      "openrouter:deepseek/deepseek-chat-v3-0324",
      "openrouter:openai/o1-pro",
      "openrouter:mistralai/mistral-small-3.1-24b-instruct:free",
      "openrouter:mistralai/mistral-small-3.1-24b-instruct",
      "openrouter:allenai/olmo-2-0325-32b-instruct",
      "openrouter:google/gemma-3-4b-it:free",
      "openrouter:google/gemma-3-4b-it",
      "openrouter:google/gemma-3-12b-it:free",
      "openrouter:google/gemma-3-12b-it",
      "openrouter:cohere/command-a",
      "openrouter:openai/gpt-4o-mini-search-preview",
      "openrouter:openai/gpt-4o-search-preview",
      "openrouter:google/gemma-3-27b-it:free",
      "openrouter:google/gemma-3-27b-it",
      "openrouter:thedrummer/skyfall-36b-v2",
      "openrouter:microsoft/phi-4-multimodal-instruct",
      "openrouter:perplexity/sonar-reasoning-pro",
      "openrouter:perplexity/sonar-pro",
      "openrouter:perplexity/sonar-deep-research",
      "openrouter:qwen/qwq-32b",
      "openrouter:nousresearch/deephermes-3-llama-3-8b-preview:free",
      "openrouter:nousresearch/deephermes-3-llama-3-8b-preview",
      "openrouter:google/gemini-2.0-flash-lite-001",
      "openrouter:anthropic/claude-3.7-sonnet",
      "openrouter:anthropic/claude-3.7-sonnet:thinking",
      "openrouter:mistralai/mistral-saba",
      "openrouter:cognitivecomputations/dolphin3.0-mistral-24b:free",
      "openrouter:cognitivecomputations/dolphin3.0-mistral-24b",
      "openrouter:meta-llama/llama-guard-3-8b",
      "openrouter:openai/o3-mini-high",
      "openrouter:google/gemini-2.0-flash-001",
      "openrouter:qwen/qwen-vl-plus",
      "openrouter:aion-labs/aion-1.0",
      "openrouter:aion-labs/aion-1.0-mini",
      "openrouter:aion-labs/aion-rp-llama-3.1-8b",
      "openrouter:qwen/qwen-vl-max",
      "openrouter:qwen/qwen-turbo",
      "openrouter:qwen/qwen2.5-vl-72b-instruct:free",
      "openrouter:qwen/qwen2.5-vl-72b-instruct",
      "openrouter:qwen/qwen-plus",
      "openrouter:qwen/qwen-max",
      "openrouter:openai/o3-mini",
      "openrouter:mistralai/mistral-small-24b-instruct-2501:free",
      "openrouter:mistralai/mistral-small-24b-instruct-2501",
      "openrouter:deepseek/deepseek-r1-distill-qwen-32b",
      "openrouter:deepseek/deepseek-r1-distill-qwen-14b",
      "openrouter:perplexity/sonar-reasoning",
      "openrouter:perplexity/sonar",
      "openrouter:liquid/lfm-7b",
      "openrouter:liquid/lfm-3b",
      "openrouter:deepseek/deepseek-r1-distill-llama-70b:free",
      "openrouter:deepseek/deepseek-r1-distill-llama-70b",
      "openrouter:deepseek/deepseek-r1:free",
      "openrouter:deepseek/deepseek-r1",
      "openrouter:minimax/minimax-01",
      "openrouter:mistralai/codestral-2501",
      "openrouter:microsoft/phi-4",
      "openrouter:sao10k/l3.1-70b-hanami-x1",
      "openrouter:deepseek/deepseek-chat",
      "openrouter:sao10k/l3.3-euryale-70b",
      "openrouter:openai/o1",
      "openrouter:cohere/command-r7b-12-2024",
      "openrouter:google/gemini-2.0-flash-exp:free",
      "openrouter:meta-llama/llama-3.3-70b-instruct:free",
      "openrouter:meta-llama/llama-3.3-70b-instruct",
      "openrouter:amazon/nova-lite-v1",
      "openrouter:amazon/nova-micro-v1",
      "openrouter:amazon/nova-pro-v1",
      "openrouter:openai/gpt-4o-2024-11-20",
      "openrouter:mistralai/mistral-large-2411",
      "openrouter:mistralai/mistral-large-2407",
      "openrouter:mistralai/pixtral-large-2411",
      "openrouter:qwen/qwen-2.5-coder-32b-instruct:free",
      "openrouter:qwen/qwen-2.5-coder-32b-instruct",
      "openrouter:raifle/sorcererlm-8x22b",
      "openrouter:thedrummer/unslopnemo-12b",
      "openrouter:anthropic/claude-3.5-haiku",
      "openrouter:anthropic/claude-3.5-haiku-20241022",
      "openrouter:anthracite-org/magnum-v4-72b",
      "openrouter:anthropic/claude-3.5-sonnet",
      "openrouter:mistralai/ministral-8b",
      "openrouter:mistralai/ministral-3b",
      "openrouter:qwen/qwen-2.5-7b-instruct",
      "openrouter:nvidia/llama-3.1-nemotron-70b-instruct",
      "openrouter:inflection/inflection-3-productivity",
      "openrouter:inflection/inflection-3-pi",
      "openrouter:thedrummer/rocinante-12b",
      "openrouter:anthracite-org/magnum-v2-72b",
      "openrouter:meta-llama/llama-3.2-3b-instruct:free",
      "openrouter:meta-llama/llama-3.2-3b-instruct",
      "openrouter:meta-llama/llama-3.2-1b-instruct",
      "openrouter:meta-llama/llama-3.2-90b-vision-instruct",
      "openrouter:meta-llama/llama-3.2-11b-vision-instruct",
      "openrouter:qwen/qwen-2.5-72b-instruct:free",
      "openrouter:qwen/qwen-2.5-72b-instruct",
      "openrouter:neversleep/llama-3.1-lumimaid-8b",
      "openrouter:openai/o1-mini",
      "openrouter:openai/o1-mini-2024-09-12",
      "openrouter:mistralai/pixtral-12b",
      "openrouter:cohere/command-r-plus-08-2024",
      "openrouter:cohere/command-r-08-2024",
      "openrouter:qwen/qwen-2.5-vl-7b-instruct",
      "openrouter:sao10k/l3.1-euryale-70b",
      "openrouter:microsoft/phi-3.5-mini-128k-instruct",
      "openrouter:nousresearch/hermes-3-llama-3.1-70b",
      "openrouter:nousresearch/hermes-3-llama-3.1-405b",
      "openrouter:openai/chatgpt-4o-latest",
      "openrouter:sao10k/l3-lunaris-8b",
      "openrouter:openai/gpt-4o-2024-08-06",
      "openrouter:meta-llama/llama-3.1-405b",
      "openrouter:meta-llama/llama-3.1-8b-instruct",
      "openrouter:meta-llama/llama-3.1-405b-instruct",
      "openrouter:meta-llama/llama-3.1-70b-instruct",
      "openrouter:mistralai/mistral-nemo:free",
      "openrouter:mistralai/mistral-nemo",
      "openrouter:openai/gpt-4o-mini",
      "openrouter:openai/gpt-4o-mini-2024-07-18",
      "openrouter:google/gemma-2-27b-it",
      "openrouter:google/gemma-2-9b-it:free",
      "openrouter:google/gemma-2-9b-it",
      "openrouter:anthropic/claude-3.5-sonnet-20240620",
      "openrouter:sao10k/l3-euryale-70b",
      "openrouter:nousresearch/hermes-2-pro-llama-3-8b",
      "openrouter:mistralai/mistral-7b-instruct:free",
      "openrouter:mistralai/mistral-7b-instruct",
      "openrouter:mistralai/mistral-7b-instruct-v0.3",
      "openrouter:microsoft/phi-3-mini-128k-instruct",
      "openrouter:microsoft/phi-3-medium-128k-instruct",
      "openrouter:openai/gpt-4o",
      "openrouter:openai/gpt-4o:extended",
      "openrouter:meta-llama/llama-guard-2-8b",
      "openrouter:openai/gpt-4o-2024-05-13",
      "openrouter:meta-llama/llama-3-8b-instruct",
      "openrouter:meta-llama/llama-3-70b-instruct",
      "openrouter:mistralai/mixtral-8x22b-instruct",
      "openrouter:microsoft/wizardlm-2-8x22b",
      "openrouter:openai/gpt-4-turbo",
      "openrouter:anthropic/claude-3-haiku",
      "openrouter:anthropic/claude-3-opus",
      "openrouter:mistralai/mistral-large",
      "openrouter:openai/gpt-3.5-turbo-0613",
      "openrouter:openai/gpt-4-turbo-preview",
      "openrouter:mistralai/mistral-small",
      "openrouter:mistralai/mistral-tiny",
      "openrouter:mistralai/mistral-7b-instruct-v0.2",
      "openrouter:mistralai/mixtral-8x7b-instruct",
      "openrouter:neversleep/noromaid-20b",
      "openrouter:alpindale/goliath-120b",
      "openrouter:openrouter/auto",
      "openrouter:openai/gpt-4-1106-preview",
      "openrouter:openai/gpt-3.5-turbo-instruct",
      "openrouter:mistralai/mistral-7b-instruct-v0.1",
      "openrouter:openai/gpt-3.5-turbo-16k",
      "openrouter:mancer/weaver",
      "openrouter:undi95/remm-slerp-l2-13b",
      "openrouter:gryphe/mythomax-l2-13b",
      "openrouter:openai/gpt-3.5-turbo",
      "openrouter:openai/gpt-4",
      "openrouter:openai/gpt-4-0314"
    ],
    "model_count": 552
  },
  "Qwen": {
    "provider_info": {
      "id": "Qwen",
      "object": "provider",
      "created": 0,
      "url": "https://chat.qwen.ai",
      "label": null
    },
    "models": [
      "qwen3-max-preview",
      "qwen-plus-2025-09-11",
      "qwen3-235b-a22b",
      "qwen3-coder-plus",
      "qwen3-30b-a3b",
      "qwen3-coder-30b-a3b-instruct",
      "qwen-max-latest",
      "qwen-plus-2025-01-25",
      "qwq-32b",
      "qwen-turbo-2025-02-11",
      "qwen2.5-omni-7b",
      "qvq-72b-preview-0310",
      "qwen2.5-vl-32b-instruct",
      "qwen2.5-14b-instruct-1m",
      "qwen2.5-coder-32b-instruct",
      "qwen2.5-72b-instruct"
    ],
    "model_count": 16
  },
  "QwenCode": {
    "provider_info": {
      "id": "QwenCode",
      "object": "provider",
      "created": 0,
      "url": "https://qwen.ai",
      "label": "Qwen Code ü§ñ"
    },
    "models": [
      "qwen3-coder-plus",
      "qwen-vl-max-latest"
    ],
    "model_count": 2
  },
  "Qwen_Qwen_2_5": {
    "provider_info": {
      "id": "Qwen_Qwen_2_5",
      "object": "provider",
      "created": 0,
      "url": "https://qwen-qwen2-5.hf.space",
      "label": "Qwen Qwen-2.5"
    },
    "models": [
      "qwen-2.5"
    ],
    "model_count": 1
  },
  "Qwen_Qwen_2_5M": {
    "provider_info": {
      "id": "Qwen_Qwen_2_5M",
      "object": "provider",
      "created": 0,
      "url": "https://qwen-qwen2-5-1m-demo.hf.space",
      "label": "Qwen Qwen-2.5M"
    },
    "models": [
      "qwen-2.5-1m"
    ],
    "model_count": 1
  },
  "Qwen_Qwen_2_5_Max": {
    "provider_info": {
      "id": "Qwen_Qwen_2_5_Max",
      "object": "provider",
      "created": 0,
      "url": "https://qwen-qwen2-5-max-demo.hf.space",
      "label": "Qwen Qwen-2.5-Max"
    },
    "models": [
      "qwen-2.5-max"
    ],
    "model_count": 1
  },
  "Qwen_Qwen_2_72B": {
    "provider_info": {
      "id": "Qwen_Qwen_2_72B",
      "object": "provider",
      "created": 0,
      "url": "https://qwen-qwen2-72b-instruct.hf.space",
      "label": "Qwen Qwen-2.72B"
    },
    "models": [
      "qwen-2-72b"
    ],
    "model_count": 1
  },
  "Qwen_Qwen_3": {
    "provider_info": {
      "id": "Qwen_Qwen_3",
      "object": "provider",
      "created": 0,
      "url": "https://qwen-qwen3-demo.hf.space",
      "label": "Qwen Qwen-3"
    },
    "models": [
      "qwen-3-14b",
      "qwen-3-30b-a3b",
      "qwen-3-8b",
      "qwen-3-32b",
      "qwen-3-4b",
      "qwen-3-0.6b",
      "qwen-3-1.7b",
      "qwen-3-235b"
    ],
    "model_count": 8
  },
  "Replicate": {
    "provider_info": {
      "id": "Replicate",
      "object": "provider",
      "created": 0,
      "url": "https://replicate.com",
      "label": null
    },
    "models": [
      "meta/meta-llama-3-70b-instruct"
    ],
    "model_count": 1
  },
  "StabilityAI_SD35Large": {
    "provider_info": {
      "id": "StabilityAI_SD35Large",
      "object": "provider",
      "created": 0,
      "url": "https://stabilityai-stable-diffusion-3-5-large.hf.space",
      "label": "StabilityAI SD-3.5-Large"
    },
    "models": [
      "sd-3.5-large"
    ],
    "model_count": 1
  },
  "StringableInference": {
    "provider_info": {
      "id": "StringableInference",
      "object": "provider",
      "created": 0,
      "url": "https://stringable-inference.onrender.com",
      "label": "Stringable Inference"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/StringableInference/models"
  },
  "TeachAnything": {
    "provider_info": {
      "id": "TeachAnything",
      "object": "provider",
      "created": 0,
      "url": "https://www.teach-anything.com",
      "label": null
    },
    "models": [
      "gemma"
    ],
    "model_count": 1
  },
  "ThebApi": {
    "provider_info": {
      "id": "ThebApi",
      "object": "provider",
      "created": 0,
      "url": "https://theb.ai",
      "label": "TheB.AI API"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/ThebApi/models"
  },
  "Together": {
    "provider_info": {
      "id": "Together",
      "object": "provider",
      "created": 0,
      "url": "https://together.xyz",
      "label": "Together"
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/Together/models"
  },
  "Video": {
    "provider_info": {
      "id": "Video",
      "object": "provider",
      "created": 0,
      "url": null,
      "label": null
    },
    "models": [
      "search",
      "sora"
    ],
    "model_count": 2
  },
  "WeWordle": {
    "provider_info": {
      "id": "WeWordle",
      "object": "provider",
      "created": 0,
      "url": "https://chat-gpt.com",
      "label": "WeWordle"
    },
    "models": [
      "gpt-4"
    ],
    "model_count": 1
  },
  "WhiteRabbitNeo": {
    "provider_info": {
      "id": "WhiteRabbitNeo",
      "object": "provider",
      "created": 0,
      "url": "https://www.whiterabbitneo.com",
      "label": null
    },
    "models": [],
    "model_count": 0
  },
  "Yqcloud": {
    "provider_info": {
      "id": "Yqcloud",
      "object": "provider",
      "created": 0,
      "url": "https://chat9.yqcloud.top",
      "label": null
    },
    "models": [
      "gpt-4"
    ],
    "model_count": 1
  },
  "Yupp": {
    "provider_info": {
      "id": "Yupp",
      "object": "provider",
      "created": 0,
      "url": "https://yupp.ai",
      "label": null
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/Yupp/models"
  },
  "xAI": {
    "provider_info": {
      "id": "xAI",
      "object": "provider",
      "created": 0,
      "url": "https://console.x.ai",
      "label": null
    },
    "models": [],
    "model_count": 0,
    "error": "500 Server Error: Internal Server Error for url: http://localhost:8081/api/xAI/models"
  },
  "AnyProvider": {
    "provider_info": {
      "id": "AnyProvider",
      "object": "provider",
      "created": 0,
      "url": null,
      "label": null
    },
    "models": [
      "default",
      "gpt-4",
      "gpt-4o",
      "gpt-4o-mini",
      "gpt-4o-mini-audio-preview",
      "gpt-4o-mini-tts",
      "o1",
      "o1-mini",
      "o3-mini",
      "o3-mini-high",
      "o4-mini",
      "o4-mini-high",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.1-nano",
      "gpt-4.5",
      "gpt-oss-120b",
      "dall-e-3",
      "gpt-image",
      "meta-ai",
      "llama-2-7b",
      "llama-2-70b",
      "llama-3-8b",
      "llama-3-70b",
      "llama-3.1-8b",
      "llama-3.1-70b",
      "llama-3.1-405b",
      "llama-3.2-1b",
      "llama-3.2-3b",
      "llama-3.2-11b",
      "llama-3.2-90b",
      "llama-3.3-70b",
      "llama-4-scout",
      "llama-4-maverick",
      "mistral-7b",
      "mixtral-8x7b",
      "mistral-nemo",
      "mistral-small-24b",
      "mistral-small-3.1-24b",
      "hermes-2-dpo",
      "phi-4",
      "phi-4-multimodal",
      "phi-4-reasoning-plus",
      "wizardlm-2-7b",
      "wizardlm-2-8x22b",
      "gemini-2.0",
      "gemini-2.0-flash",
      "gemini-2.0-flash-thinking",
      "gemini-2.0-flash-thinking-with-apps",
      "gemini-2.5-flash",
      "gemini-2.5-pro",
      "codegemma-7b",
      "gemma-2b",
      "gemma-1.1-7b",
      "gemma-2-9b",
      "gemma-2-27b",
      "gemma-3-4b",
      "gemma-3-12b",
      "gemma-3-27b",
      "gemma-3n-e4b",
      "blackboxai",
      "command-r",
      "command-r-plus",
      "command-r7b",
      "command-a",
      "qwen-1.5-7b",
      "qwen-2-72b",
      "qwen-2-vl-7b",
      "qwen-2-vl-72b",
      "qwen-2.5",
      "qwen-2.5-7b",
      "qwen-2.5-72b",
      "qwen-2.5-coder-32b",
      "qwen-2.5-1m",
      "qwen-2.5-max",
      "qwen-2.5-vl-72b",
      "qwen-3-235b",
      "qwen-3-32b",
      "qwen-3-30b",
      "qwen-3-14b",
      "qwen-3-4b",
      "qwen-3-1.7b",
      "qwen-3-0.6b",
      "qwq-32b",
      "deepseek-v3",
      "deepseek-r1",
      "deepseek-r1-turbo",
      "deepseek-r1-distill-llama-70b",
      "deepseek-r1-distill-qwen-1.5b",
      "deepseek-r1-distill-qwen-14b",
      "deepseek-r1-distill-qwen-32b",
      "deepseek-prover-v2",
      "deepseek-prover-v2-671b",
      "deepseek-v3-0324",
      "deepseek-v3-0324-turbo",
      "deepseek-r1-0528",
      "deepseek-r1-0528-turbo",
      "janus-pro-7b",
      "grok-2",
      "grok-3",
      "grok-3-r1",
      "kimi-k2",
      "sonar",
      "sonar-pro",
      "sonar-reasoning",
      "sonar-reasoning-pro",
      "r1-1776",
      "nemotron-70b",
      "dolphin-2.6",
      "dolphin-2.9",
      "airoboros-70b",
      "lzlv-70b",
      "aria",
      "evil",
      "sdxl-turbo",
      "sd-3.5-large",
      "flux",
      "flux-pro",
      "flux-dev",
      "flux-schnell",
      "flux-redux",
      "flux-depth",
      "flux-canny",
      "flux-kontext",
      "flux-dev-lora",
      "auto",
      "gpt-5",
      "gpt-5-instant",
      "gpt-5-thinking",
      "PollinationsAI:openai",
      "PollinationsAI:evil",
      "PollinationsAI:deepseek-r1-0528",
      "PollinationsAI:gemini-2.5-flash-lite",
      "PollinationsAI:mistral-small-3.1-24b",
      "PollinationsAI:nova-micro-v1",
      "PollinationsAI:gpt-5-nano",
      "PollinationsAI:gpt-4o-mini-audio-preview",
      "PollinationsAI:openai-fast",
      "PollinationsAI:gpt-4.1",
      "PollinationsAI:o4-mini",
      "PollinationsAI:qwen-2.5-coder-32b",
      "PollinationsAI:llama-roblox",
      "PollinationsAI:bidara",
      "PollinationsAI:midijourney",
      "PollinationsAI:mirexa",
      "PollinationsAI:rtist",
      "PollinationsAI:unity",
      "PollinationsAI:flux",
      "PollinationsAI:turbo",
      "PollinationsAI:kontext",
      "PollinationsAI:openai-audio",
      "PollinationsAI:alloy",
      "PollinationsAI:echo",
      "PollinationsAI:fable",
      "PollinationsAI:onyx",
      "PollinationsAI:nova",
      "PollinationsAI:shimmer",
      "PollinationsAI:coral",
      "PollinationsAI:verse",
      "PollinationsAI:ballad",
      "PollinationsAI:ash",
      "PollinationsAI:sage",
      "PollinationsAI:amuch",
      "PollinationsAI:dan",
      "gemini-2.5-flash-lite",
      "nova-micro-v1",
      "gpt-5-nano",
      "llama-roblox",
      "grok-4",
      "grok-4-heavy",
      "grok-4-reasoning",
      "grok-3-reasoning",
      "grok-3-mini",
      "grok-3-mini-reasoning",
      "grok-2-image",
      "grok",
      "model-router",
      "gpt-5-chat",
      "gpt-4o-mini-audio",
      "flux-kontext-pro",
      "qwen-3-235b-a22b",
      "qwen-3-coder-plus",
      "qwen-3-30b-a3b",
      "qwen-3-coder-30b-a3b",
      "qwen-max",
      "qwen-plus",
      "qwen-turbo",
      "qwen-2.5-omni-7b",
      "qvq-72b-preview-0310",
      "qwen-2.5-vl-32b",
      "qwen-2.5-14b-1m",
      "glm-4.5",
      "glm-4.5-air",
      "glm-4.5v",
      "glm-4-32b",
      "glm-4.1v-9b-thinking",
      "z1-rumination",
      "z1-32b",
      "chatglm",
      "deepcoder-14b",
      "qwq-32b-arliai-rpr",
      "dolphin-mistral-24b-venice-edition",
      "dolphin3.0-mistral-24b",
      "dolphin3.0-r1-mistral-24b",
      "deepseek-chat-v3-0324",
      "deepseek-chat-v3.1",
      "deepseek-r1-0528-qwen-3-8b",
      "gemini-2.0-flash-exp",
      "gemini-2.5-flash-image",
      "gemma-2-9b-it",
      "gemma-3-12b-it",
      "gemma-3-27b-it",
      "gemma-3-4b-it",
      "gemma-3n-e2b-it",
      "gemma-3n-e4b-it",
      "llama-3.3-8b",
      "mai-ds-r1",
      "devstral-small-2505",
      "mistral-small-24b-2501",
      "mistral-small-3.2-24b",
      "kimi-dev-72b",
      "kimi-vl-a3b-thinking",
      "deephermes-3-llama-3-8b",
      "llama-3.1-nemotron-ultra-253b",
      "gpt-oss-20b",
      "qwen-3-8b",
      "qwen-3-coder",
      "reka-flash-3",
      "shisa-v2-llama-3.3-70b",
      "hunyuan-a13b",
      "deepseek-r1t-chimera",
      "deepseek-r1t2-chimera",
      "deepseek-llama-3.3-70b",
      "apriel-5b",
      "hermes-3-llama-3.1-405b",
      "deepseek-v3.1",
      "qwen-3-coder-480b-a35b-turbo",
      "olmocr-7b-0725",
      "qwen-3-235b-a22b-thinking-2507",
      "qwen-3-coder-480b-a35b",
      "qwen-3-235b-a22b-2507",
      "llama-4-maverick-17b-128e-turbo",
      "llama-4-maverick-17b-128e",
      "llama-4-scout-17b-16e",
      "devstral-small-2507",
      "mistral-small-3.2-24b-2506",
      "llama-guard-4-12b",
      "claude-4-opus",
      "claude-4-sonnet",
      "deepseek",
      "llama-3.3-70b-turbo",
      "hermes-4-70b",
      "command-a-translate25",
      "hermes-4-405b",
      "qwen-3-30b-a3b-2507",
      "qwen-3-4b-2507",
      "mistral-7b-v0.2",
      "qwen-3-4b-thinking-2507",
      "tinyllama-1.1b-chat-v1.0",
      "llama-3.2-11b-vision",
      "command-r-plus24",
      "llama-3.1-nemotron-70b",
      "mistral-nemo-2407",
      "phi-3.5-mini",
      "uso",
      "qwen-image",
      "chroma1-hd",
      "compass-flux.1",
      "stable-diffusion-xl-base-1.0",
      "qwen-image-lightning",
      "raena-qwen-image",
      "boreal-qwen-image",
      "qwen-.image.edit.inpainting",
      "chroma1-base",
      "pj0.qwen-image.realistic.fp8.hf.stage.2",
      "llama-3",
      "qvq-72b",
      "stable-diffusion-3.5-large",
      "sdxl-1.0",
      "wan2.2-t2v-a14b",
      "wan2.2-ti2v-5b",
      "hunyuanvideo",
      "wan2.1-t2v-14b",
      "cogvideox-5b",
      "wan2.2-t2v-a14b-diffusers",
      "mochi-1",
      "ltx-video-0.9.5",
      "gpt-5-high",
      "claude-opus-4",
      "o3",
      "chatgpt-4o",
      "catalina",
      "command-a25",
      "amazon.nova-pro",
      "grok-3-mini-beta",
      "phantom-0821-1",
      "gemini-2.5-flash-lite-preview-thinking",
      "amazon-nova-experimental-chat",
      "claude-3-7-sonnet-20250219-thinking-32k",
      "claude-3-5-haiku",
      "mistral-medium-2505",
      "velocilux",
      "magistral-medium-2506",
      "stephen",
      "cogitolux",
      "claude-sonnet-4",
      "potato",
      "claude-3-7-sonnet",
      "minimax-m1",
      "claude-sonnet-4-20250514-thinking-32k",
      "qwen-3-235b-a22b-no-thinking",
      "claude-opus-4-20250514-thinking-16k",
      "stephen-vision-csfix",
      "mistral-small-2506",
      "grok-3-mini-high",
      "grok-4-0709",
      "claude-opus-4-1",
      "bailing-lite-250220",
      "gemini-2.5-pro-grounding-exp",
      "qwen-vl-max",
      "kimi-k2-0711",
      "step-3",
      "nightride-on",
      "eb45-vision",
      "mistral-medium-2508",
      "not-a-new-model",
      "lmarena-internal-test-only",
      "spuddle",
      "claude-opus-4-1-20250805-thinking-16k",
      "eb45-turbo",
      "deepseek-v3.1-thinking",
      "gpt-5-mini-high",
      "gpt-5-nano-high",
      "hunyuan-turbos",
      "mai-1",
      "claude-3-5-sonnet",
      "phantom-0822-1",
      "mistral-small-3.1-24b-2503",
      "gemini-2.5-flash-image-preview (nano-banana)",
      "imagen-4.0-generate",
      "flux-1-kontext-dev",
      "imagen-3.0-generate",
      "ideogram",
      "photon",
      "recraft",
      "anonymous-bot-0514",
      "flux-1.1-pro",
      "ideogram-v3-quality",
      "seedream-3",
      "lucid-origin",
      "gpt-image-1",
      "imagen-4.0-ultra-generate",
      "gemini-2.0-flash-preview-image-generation",
      "flux-1-kontext-pro",
      "qwen-image-prompt-extend",
      "flux-1-kontext-max",
      "qwen-image-edit",
      "nano-banana",
      "seededit-3.0",
      "hidream-e1.1",
      "gpt-5-mini",
      "o1-pro",
      "claude-3-haiku",
      "mistral-large",
      "mistral-medium",
      "ministral-3b-2410",
      "ministral-3b",
      "ministral-8b-2410",
      "ministral-8b",
      "open-mistral-7b",
      "mistral-tiny",
      "mistral-tiny-2312",
      "open-mistral-nemo",
      "open-mistral-nemo-2407",
      "mistral-tiny-2407",
      "open-mixtral-8x7b",
      "mistral-small",
      "mistral-small-2312",
      "open-mixtral-8x22b",
      "open-mixtral-8x22b-2404",
      "pixtral-large-2411",
      "pixtral-large",
      "mistral-large-pixtral-2411",
      "codestral-2508",
      "codestral",
      "devstral-small",
      "pixtral-12b-2409",
      "pixtral-12b",
      "mistral-saba-2502",
      "mistral-saba",
      "magistral-medium-2507",
      "magistral-medium",
      "magistral-small-2507",
      "magistral-small",
      "mistral-moderation-2411",
      "mistral-moderation",
      "mistral-ocr-2505",
      "mistral-ocr",
      "grok-beta",
      "grok-vision-beta",
      "grok-3-fast",
      "grok-3-mini-fast",
      "grok-2-vision",
      "deepseek-chat",
      "deepseek-reasoner",
      "gemini-1.5-flash",
      "mixtral-8x22b",
      "gemini-1.5-8b-flash",
      "gemini-1.5-pro",
      "gemini-2.5-flash-thinking",
      "gemma-3-1b",
      "gpt-3.5-turbo",
      "gpt-4-turbo",
      "gpt-4o-search",
      "gpt-4o-mini-search",
      "hermes-2-pro",
      "hermes-3-70b",
      "hermes-3-405b",
      "deephermes-3-8b",
      "deephermes-3-24b",
      "phi-3-mini",
      "phi-3-medium",
      "phi-4-reasoning",
      "claude-3.7-sonnet",
      "claude-3.7-sonnet-thinking",
      "claude-3.5-haiku",
      "claude-3.5-sonnet",
      "claude-3-opus",
      "claude-3-sonnet",
      "claude-2.1",
      "claude-2",
      "claude-2.0",
      "reka-flash",
      "command",
      "qwen-vl-plus",
      "qwen-2.5-vl-7b",
      "qwen-2.5-coder-7b",
      "qwen-2.5-vl-3b",
      "deepseek-prover",
      "deepseek-r1-zero",
      "deepseek-r1-distill-llama-8b",
      "deepseek-coder",
      "inflection-3-productivity",
      "inflection-3-pi",
      "grok-3-beta",
      "sonar-deep-research",
      "llama-3.1-sonar-small-online",
      "llama-3.1-sonar-large-online",
      "nemotron-49b",
      "nemotron-253b",
      "glm-4",
      "glm-z1-32b",
      "glm-4-9b",
      "glm-z1-9b",
      "glm-z1-rumination-32b",
      "minimax",
      "dolphin-3.0-r1-24b",
      "dolphin-3.0-24b",
      "dolphin-8x22b",
      "kimi-vl-thinking",
      "moonlight-16b",
      "qwerky-72b",
      "lfm-7b",
      "lfm-3b",
      "lfm-40b",
      "deepseek-coder-6.7b-base",
      "deepseek-coder-6.7b",
      "deepseek-math-7b",
      "deepseek-distill-qwen-32b",
      "discolm-german-7b",
      "falcon-7b",
      "gemma-7b",
      "hermes-2-pro-mistral-7b",
      "llama-2-13b",
      "llama-2-7b-fp16",
      "llama-guard-3-8b",
      "llama-guard-7b",
      "mistral-7b-v0.1",
      "neural-7b-v3-1",
      "openchat-3.5-0106",
      "openhermes-2.5-mistral-7b",
      "phi-2",
      "qwen-1.5-0.5b",
      "qwen-1.5-1.8b",
      "qwen-1.5-14b",
      "sqlcoder-7b-2",
      "starling-lm-7b-beta",
      "tinyllama-1.1b-v1.0",
      "una-cybertron-7b-v2",
      "zephyr-7b-beta",
      "discolm-german-7b-v1",
      "llamaguard-7b",
      "qwen1.5-0.5b",
      "una-cybertron-7b-v2-bf16",
      "command-r24",
      "command-r7b24",
      "command-r7b-arabic25",
      "flux-kontext-dev",
      "janus-pro-7b-image",
      "video"
    ],
    "model_count": 500
  }
}